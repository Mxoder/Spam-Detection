# <center>机器学习大作业报告 - 垃圾邮件识别</center>





[TOC]

## 最终结果

![](resource\最终结果.png)

- 准确率：99.65%
- 排名：1



## 团队分工

- 王乐：前期调研、框架讨论、传统机器学习方法探究、SVM 实现
- 王艺杰：前期调研、框架讨论、数据分析、数据预处理与增强
- 张贤韬：前期调研、框架讨论、Naive Bayes 实现、Bert 实现、超参数调优探索
- 李泰川：前期调研、框架讨论、深度学习方法探究、LSTM 实现

<div style="page-break-before:always;"></div>

## 一、问题介绍



<div style="page-break-before:always;"></div>

## 二、方法描述

### （一）数据分析与预处理



### （二）模型探索

#### 1. Naive Bayes

一般有五种常用的朴素贝叶斯算法：

##### 1.1 BernoulliNB - 伯努利朴素贝叶斯
模型适用于多元伯努利分布，即每个特征都是二值变量，如果不是二值变量，该模型可以先对变量进行二值化。

在文档分类中特征是单词是否出现，如果该单词在某文件中出现了即为 1，否则为 0。

在文本分类中，统计词语是否出现的向量(word occurrence vectors)，而非统计词语出现次数的向量(word count vectors)。

BernoulliNB 可能在一些数据集上表现得更好，特别是那些更短的文档。如果时间允许，一般会对两个模型都进行评估。


##### 1.2 CategoricalNB - 类朴素贝叶斯
对分类分布的数据实施分类朴素贝叶斯算法，专用于离散数据集， 它假定由索引描述的每个特征都有其自己的分类分布。

对于训练集中的每个特征 $X$，CategoricalNB 估计以类 $y$ 为条件的 $X$ 的每个特征 $i$ 的分类分布。

样本的索引集定义为 $J = 1, …, m$，其中 $m$ 为样本数。


##### 1.3 GaussianNB - 高斯朴素贝叶斯
特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。这种模型假设特征符合高斯分布。


##### 1.4 MultinomialNB - 多项式朴素贝叶斯
特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。

不支持负数，所以输入变量特征的时候，不用 `StandardScaler` 进行标准化数据，可以使用 `MinMaxScaler` 进行归一化。

这个模型假设特征复合多项式分布，是一种非常典型的文本分类模型，模型内部带有平滑参数 `alpha`。


##### 1.5 ComplementNB - 补充朴素贝叶斯
是 MultinomialNB 模型的一个变种，实现了补码朴素贝叶斯(CNB)算法。

CNB 是标准多项式朴素贝叶斯(MNB)算法的一种改进，比较适用于不平衡的数据集，在文本分类上的结果通常比 MultinomialNB 模型好。

具体来说，CNB 使用来自每个类的补数的统计数据来计算模型的权重。

CNB 的发明者的研究表明，CNB 的参数估计比 MNB 的参数估计更稳定。



#### 2. SVM



#### 3. LSTM



#### 4. BERT

BERT（Bidirectional Encoder Representations from Transformers）是一种基于 Transformer 架构的预训练语言模型。它通过无监督学习从大规模文本语料中预训练得到的通用语言表示，可以捕捉到丰富的语义信息。BERT 具有以下特点：

- 双向性：BERT 通过双向上下文建模来理解单词的含义，而不仅仅是依赖于左边或右边的上下文。
- 预训练和微调：BERT 首先在大规模语料上进行预训练，然后在特定任务上进行微调，因此可以适应各种自然语言处理任务。
- Transformer 架构：BERT 模型使用 Transformer 的编码器结构，使其能够处理长距离依赖关系，并具有较强的并行计算能力。
- 较强的语义理解能力：BERT 通过预训练学习到了丰富的语义信息，可以更好地理解文本含义

![](resource\bert原理结构图.png)

现如今，BERT 在自然语言处理领域中有广泛的应用，包括文本分类、命名实体识别、情感分析、问答系统等任务。它在这些任务中展现出了优异的性能，是当前最为广泛应用的模型之一。因此，我们重点考虑应用 BERT 来解决本问题。



<div style="page-break-before:always;"></div>

## 三、具体训练

### （一）Naive Bayes



### （二）SVM



### （三）LSTM



### （四）BERT

#### 1. 超参数经验

#### 2. 自定义任务头

#### 3. 技巧

##### （1）词元阈值过滤

##### （2）假标签法



<div style="page-break-before:always;"></div>

## 四、Optuna 自动调参

