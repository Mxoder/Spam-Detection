{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpICMxO9S9sm"
   },
   "source": [
    "# 垃圾邮件识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvIhaWk7THNh"
   },
   "source": [
    "## 1. 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 环境搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCboOwbWS7E0"
   },
   "outputs": [],
   "source": [
    "# !pip install -q numpy           # 已有 numpy 则无需重复安装\n",
    "# !pip install -q pandas          # 已有 pandas 则无需重复安装\n",
    "# !pip install -q matplotlib      # 已有 matplotlib 则无需重复安装\n",
    "# !pip install -q torch           # 已有 pytorch 则无需重复安装\n",
    "# !pip install -q seaborn         # 已有 seaborn 则无需重复安装\n",
    "# !pip install -q chardet         # 已有 chardet 则无需重复安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42502,
     "status": "ok",
     "timestamp": 1700174830798,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "1PXIIkYwT5tG",
    "outputId": "f6f84c6f-a5de-4841-d75d-103eb68a4ff9"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers    # huggingface 的集成工具库\n",
    "!pip install -q accelerate      # 加速库\n",
    "!pip install -q datasets        # 数据包\n",
    "!pip install -q optuna          # 调优\n",
    "!pip install -q tqdm            # 进度条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "# 检测编码\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 原文件并非 utf-8 编码格式\n",
    "df_tr = pd.read_csv('train.csv', encoding=detect_encoding('train.csv'))             # df_train\n",
    "df_te = pd.read_csv('test.csv', encoding=detect_encoding('test.csv'), header=None)  # df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD5ZnkzqUNFz"
   },
   "source": [
    "## 2. 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1700177309015,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "2S8PZVXfUX4_",
    "outputId": "38bb66f9-615b-46d6-ae0a-a54305169c0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>3533</td>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>3534</td>\n",
       "      <td>ham</td>\n",
       "      <td>Good evening! How are you?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>3535</td>\n",
       "      <td>ham</td>\n",
       "      <td>I'm at home. Please call</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>3536</td>\n",
       "      <td>ham</td>\n",
       "      <td>Oic cos me n my sis got no lunch today my dad ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>3537</td>\n",
       "      <td>ham</td>\n",
       "      <td>Mmmmm ... It was sooooo good to wake to your w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3537 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    v1                                                 v2  \\\n",
       "0        1   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1        2   ham                      Ok lar... Joking wif u oni...   \n",
       "2        3  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        4   ham  U dun say so early hor... U c already then say...   \n",
       "4        5   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...   ...                                                ...   \n",
       "3532  3533   ham                             Sorry, I'll call later   \n",
       "3533  3534   ham                         Good evening! How are you?   \n",
       "3534  3535   ham                           I'm at home. Please call   \n",
       "3535  3536   ham  Oic cos me n my sis got no lunch today my dad ...   \n",
       "3536  3537   ham  Mmmmm ... It was sooooo good to wake to your w...   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0           NaN        NaN        NaN  \n",
       "1           NaN        NaN        NaN  \n",
       "2           NaN        NaN        NaN  \n",
       "3           NaN        NaN        NaN  \n",
       "4           NaN        NaN        NaN  \n",
       "...         ...        ...        ...  \n",
       "3532        NaN        NaN        NaN  \n",
       "3533        NaN        NaN        NaN  \n",
       "3534        NaN        NaN        NaN  \n",
       "3535        NaN        NaN        NaN  \n",
       "3536        NaN        NaN        NaN  \n",
       "\n",
       "[3537 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 df_tr\n",
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700177309635,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "Y4oEMXPsUeAy",
    "outputId": "ed46f363-4ebf-4415-cc59-fc09b590505b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ba274d35-48b4-4e21-b612-90d774bdf5c7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are pleased to inform that your application...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happen dear. Why you silent. I am tensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll get there at 3, unless you guys want me t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are not coughing then its nothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ÌÏ come lt 25 n pass to me lar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2035 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba274d35-48b4-4e21-b612-90d774bdf5c7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ba274d35-48b4-4e21-b612-90d774bdf5c7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ba274d35-48b4-4e21-b612-90d774bdf5c7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-dd1d83b3-a3c6-4d92-be64-9e7efe15c356\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd1d83b3-a3c6-4d92-be64-9e7efe15c356')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-dd1d83b3-a3c6-4d92-be64-9e7efe15c356 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                      0    1    2    3\n",
       "0     We are pleased to inform that your application...  NaN  NaN  NaN\n",
       "1         What happen dear. Why you silent. I am tensed  NaN  NaN  NaN\n",
       "2     I'll get there at 3, unless you guys want me t...  NaN  NaN  NaN\n",
       "3              If you are not coughing then its nothing  NaN  NaN  NaN\n",
       "4                        ÌÏ come lt 25 n pass to me lar  NaN  NaN  NaN\n",
       "...                                                 ...  ...  ...  ...\n",
       "2030  This is the 2nd time we have tried 2 contact u...  NaN  NaN  NaN\n",
       "2031              Will Ì_ b going to esplanade fr home?  NaN  NaN  NaN\n",
       "2032  Pity, * was in mood for that. So...any other s...  NaN  NaN  NaN\n",
       "2033  The guy did some bitching but I acted like i'd...  NaN  NaN  NaN\n",
       "2034                         Rofl. Its true to its name  NaN  NaN  NaN\n",
       "\n",
       "[2035 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 df_te\n",
    "df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1700177311297,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "_Gm9vUB0Ug3R",
    "outputId": "0760c158-9a21-432e-fe45-eae48b34aafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3537 entries, 0 to 3536\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          3537 non-null   int64 \n",
      " 1   v1          3537 non-null   object\n",
      " 2   v2          3537 non-null   object\n",
      " 3   Unnamed: 3  30 non-null     object\n",
      " 4   Unnamed: 4  9 non-null      object\n",
      " 5   Unnamed: 5  4 non-null      object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 165.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看 df_tr.info()\n",
    "df_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700177311297,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "w4Qog9Z0Uw7K",
    "outputId": "7abd9555-c6e1-4834-8fde-d0a6f2eb1888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2035 entries, 0 to 2034\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       2035 non-null   object\n",
      " 1   1       20 non-null     object\n",
      " 2   2       3 non-null      object\n",
      " 3   3       2 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 63.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看 df_te.info()\n",
    "df_te.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG2UopMrUm2m"
   },
   "source": [
    "可以看到，数据有后三列杂列，这是由于 csv 解析逗号导致的，故合并后三列并重新规范命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700177904777,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "JX36gCxPUlr0"
   },
   "outputs": [],
   "source": [
    "# 将每行的第三列之后的内容合并到第三列\n",
    "df_tr['v2'] = df_tr.apply(lambda row: ','.join(map(str, filter(lambda x: pd.notna(x), row[2:]))), axis=1)\n",
    "df_tr = df_tr.iloc[:, :3]\n",
    "\n",
    "# 规范命名\n",
    "df_tr = df_tr[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'content'})\n",
    "df_te = df_te[[0]].rename(columns={0: 'content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700177314328,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "21kwu_rjVD99",
    "outputId": "5942c2b6-ca7b-4ef5-f7f7-f63ee7360d34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good evening! How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm at home. Please call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oic cos me n my sis got no lunch today my dad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mmmmm ... It was sooooo good to wake to your w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "3532   ham                             Sorry, I'll call later\n",
       "3533   ham                         Good evening! How are you?\n",
       "3534   ham                           I'm at home. Please call\n",
       "3535   ham  Oic cos me n my sis got no lunch today my dad ...\n",
       "3536   ham  Mmmmm ... It was sooooo good to wake to your w...\n",
       "\n",
       "[3537 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次查看 df_tr\n",
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1700177315475,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "hiO_PMWtVJ9U",
    "outputId": "67702185-a070-4fde-ae1b-b8107b656cbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are pleased to inform that your application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happen dear. Why you silent. I am tensed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll get there at 3, unless you guys want me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are not coughing then its nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ÌÏ come lt 25 n pass to me lar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2035 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content\n",
       "0     We are pleased to inform that your application...\n",
       "1         What happen dear. Why you silent. I am tensed\n",
       "2     I'll get there at 3, unless you guys want me t...\n",
       "3              If you are not coughing then its nothing\n",
       "4                        ÌÏ come lt 25 n pass to me lar\n",
       "...                                                 ...\n",
       "2030  This is the 2nd time we have tried 2 contact u...\n",
       "2031              Will Ì_ b going to esplanade fr home?\n",
       "2032  Pity, * was in mood for that. So...any other s...\n",
       "2033  The guy did some bitching but I acted like i'd...\n",
       "2034                         Rofl. Its true to its name\n",
       "\n",
       "[2035 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次查看 df_te\n",
    "df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 2360,
     "status": "ok",
     "timestamp": 1700175110670,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "85u1nVl3VQzB",
    "outputId": "e256957b-16ea-45fa-b333-2940ba18bb7d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_tr 分布 - 直方图\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_tr.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAHiCAYAAACJPuQnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDE0lEQVR4nO3deXxU5aE//s85s09C9pAASYAQCEvCHhRBZHMBwX2ptr2i1rpUvUpvte21Wv3Vattr63Lb2npb6xe3tlStyiayGVBZw74nAcISEkIWktnPOb8/IhGEATKZmefMOZ/368WLzP4JAeYzz3nO80iapmkgIiIiOgtZdAAiIiLSLxYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwrKIDEFHshbQQQloIAQQQ1IKn/VKhAgA0aKc95uRlDRossMAqWWGDDVbJetrXNskGK6yQJCnu3xcRxR6LAlEC8mt+tKqt8KpeeDQPPKrntN9PXu/TfAhpoY4yEEt2yQ6X5IJbcsMlu+CSXF///tXXyXIyUuQU2CV7zPMQUXRImqZp578bEcWToiloUVvQrDajWWlGk9qEFrUFLWoLTqgn4Nf8oiN2iVNyIkVOOe1XN7kbUi2pSJVTYZX4GYZIL1gUiATSNA1NahMalAYcU46hQWlAg9KAJrXpjEMBZiFBQpqchgxLBjItmci0ZCLDkoF0OR0WySI6HpHpsCgQxUlQC6IuVIejytGOUnBcOY4QQqKjJQQZMtLkNGRaMtHd2h3dLd2RY82BQ3KIjkZkaCwKRDHSqDSiNlSLWqUWR0JH0KA0xGWugNmkyWnIteYi15KLXGsusi3ZkCWe0EUULSwKRFGgaipqlVocDB7EkdAR1Cq18Gk+0bFMyQorcqw5yLPmId+aj1xrLg9ZEHUBiwJRhI4px1ATrEFNqAaHgocQQEB0JDoLK6zoae2JfFs+8qx5yLHk8FROok5gUSC6QK1qK/YH96MmVIOaYA08mkd0JIqAQ3Kgl7UXCqwFKLQXopvcTXQkIl1jUSA6h2PKMVQFqlAZrESdUic6DsVAtiUbfW19UWgrRHdLd442EH0DiwLRKVRNxZHQEVQGK1EVrEKz2iw6EsVRspSMPrY+KLQXIt+az/UciMCiQARVU3EgdAB7AntQHayGV/OKjkQ6YIMNfW19UWwvRm9bb06IJNNiUSDTqg3VYldgF3YHdnO+AZ2TU3KiyFaEYnsxell78fAEmQqLAplKk9KEXYFd2BnYiSa1SXQcSkDJUjIG2Aeg2F6M7tbuouMQxRyLAhleQAtgZ2Andvh3oFapFR2HDCRTzkSJowSD7IPgkLlCJBkTiwIZVl2oDlv8W7ArsAtBBEXHIQOzwooiexFKHaXoae0pOg5RVLEokKEEtSB2B3Zji38LjipHRcchE8qUMzHEMQSD7IPglJ2i4xB1GYsCGcJx5Tg2+zdjZ2Bnwm/BTMZggQUD7AMw3DGccxkoobEoUEKrCdZgvW899of2i45CFFaeNQ8jnSPRx9qHZ0xQwmFRoISjair2BPdgg28DV0ukhJIhZ2CEcwQG2gdyMSdKGCwKlDCCWhDb/NtQ4a9Ai9oiOg5RxFySC0MdQzHUMRRu2S06DtE5sSiQ7nlVLyr8Fdji38Ktm8lQrLCixFGC0c7RSJKTRMchOisWBdItr+rFet96bPZv5umNZGgsDKRnLAqkOz7Vh/X+9djk28SCQKZihRWljlKMco5iYSDdYFEg3fBrflT4KlDhq0AAAdFxiIRhYSA9YVEg4UJaCBv9G7Het55zEIhOYYUVI50jMco5CnbJLjoOmRSLAgmjaRp2BXbhc9/nOKGeEB2HSLfckhsXuy7GEPsQyJIsOg6ZDIsCCXE4dBjlnnJu0kTUCZlyJsa5x6Gvra/oKGQiLAoUVy1KC1Z6V2JPcI/oKEQJK9+aj0tdlyLbmi06CpkAiwLFhV/zY613LTb6N0KBIjoOUcKTIGGQfRDGucZx0SaKKRYFirmd/p0o95bDo3lERyEyHIfkwFjnWJQ6Sjl/gWKCRYFiplFpxDLPMtSEakRHITK8bEs2JrsnI9eaKzoKGQyLAkWdoilY51uHtb61PMxAFEcSJJTYSzDONQ4O2SE6DhkEiwJF1cHgQSz1LEWj2ig6CpFpuSU3JrgnoNheLDoKGQCLAkWFV/Wi3FuOHYEdoqMQ0Vf6WPtgStIUJMvJoqNQAmNRoC6rDFRiiWcJvJpXdBQi+gaH5MBlrsswyDFIdBRKUCwKFDG/5scKzwqOIhAlgEJbISa7J3PvCOo0FgWKyIHgASxuW4xWrVV0FCK6QE7JiYnuiZy7QJ3CokCdEtSCWOldic3+zaKjEFGEimxFmOSexIWa6IKwKNAFOxw6jE/aPkGz2iw6ChF1kUty4fKky7lvBJ0XiwKdl6ZpWONbg9W+1dDAvy5ERjLSMRKXuC6BRbKIjkI6xaJA59SmtmFR2yKurkhkYDmWHExLmoZUS6roKKRDLAoUVk2wBgvbFnKPBiITsEt2THFPwQD7ANFRSGdYFOgMmqZhtW811vjW8FADkcmU2EtwmfsyWCWr6CikEywKdJo2tQ0L2xbiYOig6ChEJEimnImrk69GuiVddBTSARYF6nAoeAjz2uZxhUUigl2y40r3lSi0F4qOQoKxKBAAYLN/M1Z4VkCFKjoKEenIWOdYlDnLIEmS6CgkCIuCySmaguWe5dga2Co6ChHpVJGtCJcnXQ67ZBcdhQRgUTAxj+rBvLZ5OBw6LDoKEelcppyJGckzkGZJEx2F4oxFwaTqQnX4uO1jnFBPiI5CRAnCITkwLWkaett6i45CccSiYEK7A7uxuG0xQgiJjkJECUaChAmuCRjuHC46CsUJi4LJrPGuwRe+L0THIKIEN8IxApe6LuUkRxNgUTAJVVOx3LMcWwJbREchIoPob+uPK5Ku4OJMBseiYAIhLYQFbQtQFawSHYWIDKantSdmJs2EU3aKjkIxwqJgcF7Viw9bP0StUis6ChEZVLqcjmuTr+WmUgbFomBgzUozPmj9AE1qk+goRGRwbsmNa5KvQY41R3QUijIWBYM6GjqKD1s/5M6PRBQ3NtgwI3kGCmwFoqNQFLEoGNCh4CF82PohAgiIjkJEJmOBBdOTpnOPCANhUTCYA8ED+Kj1I66RQETCyJBxVdJV6G/vLzoKRQGLgoHsC+7Dx60fQ4EiOgoRmZwECVPdUzHYMVh0FOoiFgWDqAxUYkHbApYEItKVSe5JGOoYKjoGdQGLggHsDuzGorZF3CKaiHRpvGs8RjlHiY5BEWJRSHA7/Duw2LMYGvhjJCL9GuscizGuMaJjUARk0QEoctv92/GJ5xOWBCLSvS98X2CDb4PoGBQBFoUEtSuwC596PhUdg4jogpV7y7HZv1l0DOokFoUEVBmoxCdtHEkgosSzzLMMO/w7RMegTmBRSDD7g/uxoG0BJy4SUcJa7FmM3YHdomPQBWJRSCCHQoe4TgIRJTwNGha1LUJVgDvaJgIWhQRRF6rDh60fcsVFIjIEFSrmt83H/uB+0VHoPFgUEkCj0ogPWj9AQOPeDURkHAoUzGudh6Oho6Kj0DmwKOicR/Xgg9YP4NW8oqMQEUVdEEF82PohmpVm0VEoDBYFHQtq7f+AWtQW0VGIiGLGo3nw79Z/w6f6REehs2BR0ClN07CwbSGOKhySIyLja1Qb2+dhaZyHpTcsCjr1mfczVAU5I5iIzOOIcgQL2xaCOwvoC4uCDlX4KrDRv1F0DCKiuKsMVuIz72eiY9ApWBR0Zm9gL8q95aJjEBEJs9G/kftC6AiLgo7UhmqxqG0Rl2YmItNb6V2JfcF9omMQWBR0o01tw7zWeVxQiYgI7as3LmhbgEalUXQU02NR0AFFUzC/bT5atVbRUYiIdCOgBfBh64fwq37RUUyNRUEHPvN+hsOhw6JjEBHpTpPahAVtC3gmhEAsCoJt82/j/uxEROewP7Qfn/s+Fx3DtFgUBKoN1WKZZ5noGEREurfOtw57AntExzAlFgVBTk5e5JbRREQXZnHbYhxXjouOYTosCgKomsrJi0REnRREEPNb53OZ5zhjURDgS9+XnLxIRBSBBrUBKzwrRMcwFRaFOKsJ1mCdb53oGERECWtrYCt2BXaJjmEaLApx5FE9XHmRiCgKlrYtRZPSJDqGKbAoxImmaVjcthhtWpvoKERECS+AABa0LYCicUJ4rLEoxEmFvwL7QvtExyAiMow6pQ4rvStFxzA8FoU4OBo6is+9XCyEiCjaNvo3ojJQKTqGobEoxFhA+2p4jOslEBHFxBLPEnhUj+gYhsWiEGPlnnI0q82iYxARGZZX82KpZ6noGIbFohBDB4IHsDWwVXQMIiLDqwxWYqd/p+gYhsSiECMBLYBPPZ+KjkFEZBrLvcvRqnLF22hjUYiRck85TqgnRMcgIjINv+bHp238gBZtLAoxsD+4n4cciIgE2B/aj61+/v8bTSwKUcZGS0QkVrmnHC1Ki+gYhsGiEGXlnnLuCklEJFAAASzxLBEdwzBYFKKoJliDbYFtomMQEZnegdABbhwVJSwKUaJoCpZ5lomOQUREXyn3lMOv+UXHSHgsClGy3rcejWqj6BhERPSVNq2Ny+dHAYtCFLQoLVjrWys6BhERfcMW/xYcDR0VHSOhsShEwXLvcoQQEh2DiIi+QYOGpZ6lUDVVdJSExaLQRVWBKlQHq0XHICKiMOqUOmz2bxYdI2GxKHRBUAtihXeF6BhERHQeX3i/4PLOEWJR6IK1vrVoUbmoBxGR3gUQ4MTGCLEoRKhZacYG3wbRMYiI6ALtCOxAXahOdIyEw6IQoc+9n0OBIjoGERF1Qrm3XHSEhMOiEIHaUC12B3eLjkFERJ10MHQQVYEq0TESCotCBFZ6V4qOQEREEVrpXcnTJTsh6kVh4sSJeOSRR6L9tLpRGajEodAh0TGIiChCjWojtvi3iI6RMDii0AmqpmKVd5XoGERE1EWrfavhV7kPxIVgUeiELf4t3M+BiMgAvJqXS+9foJgUBVVV8dhjjyEjIwO5ubn4+c9/3nHbb3/7W5SWliIpKQn5+fl44IEH0Nr69SIYf/vb35CWloaPP/4YxcXFcLvduOmmm+DxePDGG2+gT58+SE9Px8MPPwxFid9ZBwEtgNW+1XF7PSIiiq1N/k1oU9tEx9C9mBSFN954A0lJSVi9ejV+/etf45lnnsHixYvbX1CW8fLLL2Pbtm144403sHTpUjz22GOnPd7j8eDll1/Gu+++i4ULF2L58uW4/vrrMX/+fMyfPx9z5szBn/70J8ydOzcW8c9qo28jvJo3bq9HRESxFUII63zrRMfQPUnTNC2aTzhx4kQoioLy8q/PVR0zZgwmT56M559//oz7z507F/fddx+OHTsGoH1E4c4778TevXvRr18/AMB9992HOXPm4OjRo0hOTgYAXHXVVejTpw9effXVaMY/q4AWwOvNr8On+WL+WkREFD8WWDArdRaS5WTRUXQrJiMKQ4cOPe1yjx49UFfXvhrWp59+iilTpqBXr17o1q0bvvvd76KhoQEej6fj/m63u6MkAEBOTg769OnTURJOXnfyOWNto28jSwIRkQEpUDiqcB4xKQo2m+20y5IkQVVV7Nu3DzNmzMDQoUPxr3/9C+vXr8fvf/97AEAgEDjn48M9Z6wFtAAq/BUxfx0iIhJjq38rTqgnRMfQrbie9bB+/XqoqooXXngBF198MQYMGIDDhw/HM0KnbfJv4mgCEZGBKVB4BsQ5xLUoFBUVIRgM4pVXXkFVVRXmzJkTlzkGkQpoAVT4OJpARGR02/3buRtwGHEtCsOGDcNvf/tb/OpXv0JJSQneeustPPfcc/GM0Cmb/Zt5pgMRkQkoULDWy1GFs4n6WQ9GEdSCeL35dRYFIiKTsMCCO1PvRJKcJDqKrnBlxjC2+reyJBARmYgCBZv8m0TH0B0WhbNQNRUb/RtFxyAiojjb4t+CoBYUHUNXWBTOYm9wLye1EBGZkE/zYbt/u+gYusKicBbrfetFRyAiIkEq/BXg9L2vsSh8w6HgIdQp8VnxkYiI9KdZbcbe4F7RMXSDReEbuAojERFt8G0QHUE3WBRO0aw0oypYJToGEREJVqvU4nBI3ysHxwuLwik2+TdBA49LERERsMnHUyUBFoUOIS2E7QHOdCUionaVwUp4VM/572hwLApf2RPYA7/mFx2DiIh0QoGCHYEdomMIx6Lwla2BraIjEBGRzmzxbzH9qZIsCgCOK8c5aYWIiM7QrDajJlQjOoZQLApo39eBiIjobLb4t4iOIJTpi0JIC/EYFBERhVUVrEKb2iY6hjCmLwqVwUr4NJ/oGEREpFMqVFPv/2D6osDDDkREdD7bAttERxDG1EWhWWnGwdBB0TGIiEjnmtVm0056N3VR2BXYJToCEREliJ2BnaIjCGHqorA7sFt0BCIiShB7AnugaIroGHFn2qJwTDmGBrVBdAwiIkoQPs2HfcF9omPEnWmLAkcTiIios8z43sGiQEREdIGqglUIakHRMeLKlEWhNlSLZrVZdAwiIkowIYRQGawUHSOuTFkUeLYDERFFymwj0qYrCpqmYU9gj+gYRESUoA4ED5jq8IPpisIR5QjaNPOu2U1ERF2jQMH+4H7RMeLGdEWhKlAlOgIRESW4qqB53ktMVxSqg9WiIxARUYLbF9wHVVNFx4gLUxWFZqUZx9XjomMQEVGC82peHAkdER0jLkxVFMw0VERERLFllvcUUxUFHnYgIqJoYVEwGL/mx6HQIdExiIjIIJrUJhxXjH842yo6QLwcCB6ACnNMPPkmVVGx8PmFWPfPdThRdwIpuSkYc9sYXPFfV0CSpI771e6qxUdPf4TKVZVQFRU5xTm46427kJ6XHva5Pc0ezP/FfGz+eDPaGtuQkZ+B6395PQZfPrjjPk2Hm/DR0x9hx6c7EPQGkdU3C7f9720oGFEAAFj6ylIsfWUpAGDKw1Mw6cFJHY/dt24f5v5oLh5d/CgsVku0/2iIiLqkOliNDEuG6BgxZZqiYObDDkteWoJVr6/C7X+4HbkDc1FTUYN3HnoHzhQnLrv3MgDAsepjeHn6y7j4Oxdj2o+nwdnNidqdtbA6wv8VCQVC+OMNf0S3rG6Y9fospPZMRWNNI1ypro77eJo8eGnaS+g/vj/u/ce9SM5KRn1lPdxpbgDA4W2HseD5BbjnnXsADXjtttdQPLkYPQf3hBJS8M8f/hO3/u5WlgQi0qWaYA1GOUeJjhFTpikKNcEa0RGEqV5TjZJpJRhyxRAAQGZBJjb8awMObDjQcZ95v5iHwZcPxjVPX9NxXVbfrHM+7+q3VsPT6MEjCx+BxWbpeO5TLXlpCdJ7peP239/ecV1m76/vc3T3UfQc3BMDJgwAAPQY3AN1u+vQc3BPLH1lKfqN7YeCkQURfudERLF1OHQYiqbAIhn3w4wpikKj0ohWrVV0DGH6jumLz9/4HHV769C9qDsObT2EqtVVuO4X1wEAVFXF9sXbMfmhyfjjjX/EoS2HkFGQgamPTsXQq4eGfd6tC7aiT1kfzP3RXGxZsAXJmckYddMoTPnPKZAtcsd9Bk4eiNdnvY7KzyuR2iMV4+8aj7F3jAXQXgzqK+vReLARmqahvrIeuYNycaz6GNa8vQY/XPrDmP/5EBFFKoggakO16GXrJTpKzJiiKBwMHRQdQagpj0yB74QPz130HCSLBE3RMP2J6Rh982gAQGt9K/ytfix5aQmm/3Q6Zv58JnYu2YnX/+N1/ODDH6BoXNFZn7dhfwP2lO/BqJtG4d6/34v6qnrM/dFcKEEFVz1+Vcd9Vr2+ChMfmIjLZ1+OAxsO4L2fvAeL3YIxt41BbnEurv7Z1fjDDX8AAMx4cgZyi3Pxh+v/0J5j6U4s/NVCWGwW3PDcDeh3Sb/4/KEREV2gmlANi0KiOxg0d1HY+P5GrP/nenz3z99F7qBcHNpyCO//9H2k5qZizG1joKkaAKBkWgkmPjARAJBXmofqNdVY9fqqsEVBUzUkZyXj1hdvhWyRkT88H81HmrHsf5d1FAVN1ZA/PB8zfjaj/XmH5uHIziNY9foqjLltDABg3J3jMO7OcR3Pu+adNXAkO9C3rC+eHfMsfrjkh2g63IQ3vvcGnqx48pzzJoiI4q0mVIOLcbHoGDFjitMjzT6i8OFTH2LKI1Mw8saR6Dm4J8puLcPE+yfi0xc/BQAkZSZBtsrILc497XE5A3LQdLAp7POm5KSge1H3jsMMJx/TcrQFoUCo4z5nfd5DZ3/e1oZWLPr1Itz4/I3Yv34/uhd1R3a/bPS/tD+UoIK6yroI/gSIiGKnNlRr6N0kDV8UjivH4dE8omMIFfAGIMnSaddJFqljJMFqt6JgRAHq9p7+JlxfWY/0/PCnRva9qC/qq+qhquppj0nJTYHVbu24zxnPu7c+7CmXH/z3B7js/suQ1isNqqJCCSodt6khFapizlNciUi/VKiGXqfH8EXBzGc7nDTkqiFY/MJibPtkGxoONGDzx5ux/A/LUXp1acd9Jj80GRXvV+CLN75AfVU9yl8rx7aF2zD+7vEd93nz/jfx0TMfdVwed+c4eBo9eP8n76Nubx22fbINi3+3+LTHTLx/Ivat24fFv12M+qp6rJ+7Hl/8vy8w/ntf3+ekXct2oW5vXcdtBSMKULenDtsXb8fnf/scskVG96LusfgjIiLqEiO/10iapmmiQ8TSvNZ52BvcKzqGUL4TPsz/5XxsmbcFrcdakZKbgpE3jsSVP7qy45M/AHz55pf49MVP0Xy4GdlF2Zj242konf51mXhl5ivIKMjAt3//7Y7rqtdU44P//gCHth5Cao9UXPydi0876wEAti3aho+f+Rj1VfXIKMjApAcmdZz1cFLAG8BvLvsN7vjLHcgrzeu4/ov/9wXm/3I+rHYrbvqfmzpO8SQi0pNcSy5uTblVdIyYMHxR+HPTn+HVvKJjEBGRgVlgwf1p9xtyPQVDH3poUVpYEoiIKOYUKKhX6kXHiAlDF4WjylHREYiIyCRqQ7WiI8SEoYuCUX9oRESkP7WKMd9zDF0UOKJARETxYtQPp4YtCpqmoS7ExXmIiCg+mtVmeFXjzYszbFFoUBsQhHFXyiIiIv0x4uEHwxaFoyEediAiovgy4uEHFgUiIqIoMeIpkoYtCkb8YRERkb41KA2iI0SdYYvCceW46AhERGQyLWqL4XaSNGRROKGeQAAB0TGIiMiEjDaqYMiiwNEEIiIShUUhARjth0RERInDaO9BhiwKHFEgIiJRWBQSAIsCERGJwqKQABpUY/2QiIgocbRpbfCpPtExosZwRaFVbUVA4xkPREQkTrPaLDpC1BiuKDQrxvnhEBFRYmpRW0RHiBrDFQUj/XCIiCgxcURBx1gUiIhItBbFOO9FhisKJ9QToiMQEZHJGelDq+GKgpF+OERElJiM9F7EokBERBRlLWoLNE0THSMqDFUUNE1Dq9oqOgYREZmcAgVtWpvoGFFhqKLg0TxQoIiOQUREZJg5c4YqCjzsQEREetGmckRBd4zyQyEiosTn1byiI0SFoYqCR/OIjkBERAQA8KjGeE8yVFHwqsZob0RElPg4oqBDHFEgIiK9MPWIwuTJk9HU1HTG9S0tLZg8eXJXM0WMIwpERKQXph5RWL58OQKBM7dy9vl8KC8v73KoSPk04+z/TUREic0oIwrWztx58+bNHV9v374dtbW1HZcVRcHChQvRq1ev6KXrJBYFIiLSC6OMKHSqKAwfPhySJEGSpLMeYnC5XHjllVeiFq6zWBSIiEgvfJoPmqZBkiTRUbqkU0WhuroamqahsLAQa9asQXZ2dsdtdrsd3bt3h8ViiXrIC+VX/cJem4iI6FQaNIQQgg020VG6pFNFoXfv3gAAVVVjEqarAjhz3gQREZEoQS0Im2SionCqPXv2YNmyZairqzujODz55JNdDtZZIS0U99ckIiI6l6AWFB2hyyIqCq+99hruv/9+ZGVlITc397TjL5IksSgQEREBCMKkReEXv/gFnn32WTz++OPRzhMxI/wwiIjIWIzwITaidRQaGxtx8803RztLlxjhh0FERMZihEMPERWFm2++GZ988km0s3QJiwIREemNEYpCRIceioqK8LOf/QxffvklSktLYbOdPqPz4Ycfjkq4zgiBRYGIiPTFCO9NkqZpWmcf1Ldv3/BPKEmoqqrqUqhI1ARr8F7re3F/XSIionCmuqdiiGOI6BhdEtGIQnV1dbRzdJkRWhsRERmLhk5/Ftcdw2wzHcHACBERUUwZoShENKJw1113nfP2v/71rxGF6YpEX0ubiIiMx7RFobGx8bTLwWAQW7duRVNT01k3i4oHCSwKRESkL0YY7Y6oKLz//vtnXKeqKu6//37069evy6GISKwbqrcgf+dfRMcgSnxlfwD6DxOdokuiNkdBlmXMnj0bv/vd76L1lJ3CEQWi6Hmvbyka+uprUTWixJT4UwGj+h1UVlYiFBJz9gGLAlF0vV18CVp7Xi46BlFikxK/KER06GH27NmnXdY0DUeOHMG8efNwxx13RCUYEYmlShLmlEzDXYEmOI6tFR2HKDGZtShUVFScdlmWZWRnZ+OFF1447xkRscIRBaLoC1hkvDXiVvzH6hZYW3aJjkOUgExaFJYtWxbtHF3GokAUGyesVswddTdu+fIlyN5DouMQJRY5ordZXelS1amvr8fKlSuxcuVK1NfXRytTRKxS4v8wiPTqqNOOj8sehGZPFx2FKLFYk0Qn6LKIikJbWxvuuusu9OjRAxMmTMCECRPQs2dP3H333fB4PNHOeEFsku38dyKiiFUnubBs9KPQLE7RUYgShy1FdIIui6gozJ49GytWrMBHH32EpqYmNDU14d///jdWrFiBH/7wh9HOeEFYFIhib0tqCtaNnA1NsoiOQpQYrN1EJ+iyiHaPzMrKwty5czFx4sTTrl+2bBluueUWIYchfKoPf2r+U9xfl8iMrjy8DwM3vSg6BpH+Xb0dSB0kOkWXRDSi4PF4kJOTc8b13bt356EHIhNY1LMPDhaLOcOJKKHYEn9EIaKiMHbsWDz11FPw+Xwd13m9Xjz99NMYO3Zs1MJ1hkWywAIOhxLFy78Kh+J4nxtFxyDSNwPMUYjoVIEXX3wRV111FfLy8jBsWPsa1ps2bYLD4cAnn3wS1YCdYZNsUDRF2OsTmc1bA8fjLn8zko58KjoKkQ5JgDVZdIgui2iOAtB++OGtt97Czp07AQCDBg3Ct7/9bbhcrqgG7IzXm19Hi9oi7PWJzMihqLhr/duwN6wTHYVIX6zJwC0nRKfosohGFJ577jnk5OTgnnvuOe36v/71r6ivr8fjjz8elXCdxXkKRPHnt8h4e8Rt+O6aFlhadouOQ6QfBpifAEQ4R+FPf/oTBg4ceMb1Q4YMwauvvtrlUJFySeJGM4jMrNlmwdzR34Pq6ik6CpF+GGB+AhBhUaitrUWPHj3OuD47OxtHjhzpcqhIuSW3sNcmMrtahx3zRz8IzZYmOgqRPlhNXBTy8/OxatWqM65ftWoVevYU94nCLbMoEIlUmezGijKu3kgEAHDlik4QFRHNUbjnnnvwyCOPIBgMYvLkyQCAJUuW4LHHHhO2MiPAokCkB5tSU5E84lGMWv8rSJoqOg6ROK5eohNERURF4Uc/+hEaGhrwwAMPIBAIAACcTicef/xx/OQnP4lqwM5IkhJ/8w0iI1iVnYNuQx9C8aaXREchEsdtjKIQ8emRANDa2oodO3bA5XKhf//+cDgc0czWafuC+/Dv1n8LzUBEX7upahN67XpddAwiMS76K9DvTtEpuqxL20wnJyejrKwMJSUlwksCwMmMRHozt3AYjve5QXQMIjEMMqLQpaKgN5yjQKQ/bw28FG09JouOQRR/BpmjYKyiILkhQRIdg4hOoUoS5pTOQCBzlOgoRPHFEQX9kSWZExqJdOjk6o1Kt/6ioxDFh8UN2NNEp4gKQxUFAEi1pIqOQERn0WyzfrV645mLtREZjkFGEwAjFgWZRYFIr2qdDiwoewiajf9OyeAMMj8BYFEgojjbm+TGZ6MfhSaLP1OKKGbceaITRI3xigIPPRDp3sa0NGwY+Sg0yXD/BRG16zZAdIKoMdy/Uo4oECWGldm52Fv6oOgYRLGReuYOy4mKRYGIhJnfqxCHB9whOgZR9KUMEp0gagxXFFyyC3bYRccgogv0z34j0NT7OtExiKJHsvDQg95xngJRYnlz4GXw5E4UHYMoOpL6AhbjfGA1ZFHItGSKjkBEnaDIEuYMvQaBjBGioxB1XapxDjsALApEpBM+i4x3Rn4HSrci0VGIusZA8xMAgxaFLEuW6AhEFIEmmwXvjf4+VGeu6ChEkUsxzhkPAIsCEenMYacdC8Y8BM2WIjoKUWR46EH/kuVkOCWn6BhEFKG9SUkoHz0bmmycCWFkIjz0kBg4qkCU2CrS0lAxYjY0bh1PicTVE7Ab68w7FgUi0q3y7rmo5OqNlEgyRotOEHWGLQo884HIGObl9cORAf8hOgbRhckcIzpB1Bm2KGRbskVHIKIo+Ue/kWjqfa3oGETnl3WR6ARRZ9iikGXJggUW0TGIKEreHDgRntzLRMcgOgcJyCgTHSLqDFsULJIFOdYc0TGIKEoUWcKbpdcikDFcdBSis0spNtxERsDARQEAci1ctIXISLxWGe+O+A6U5H6ioxCdyYDzEwCDF4Ue1h6iIxBRlDXarXiv7PtQnRwxJJ3JNN78BIBFgYgS0GGnAwvLHjbE6o2f7QBm/g/Q8weA9G3gg3Wn3/7zfwED/wtIugtIvweY+ktg9d5zP+cfPwWG/hhIubv919ingAUbz35fTQOm/erM1z7e2p4r+S5gxE+Bin2nP+4HrwMvzOvsd2twHFFIPElyErrJ3UTHIKIY2JOchJWjHk341Rvb/MCwAuD3s85++4Bc4H9nAVueB1Y+BfTJBq54HqhvCf+ceRnA898C1j8LrPsFMHkIcO1vgW0Hz7zviwsB6SxrWj37AXDCB2x4Fpg4CLjn/76+7cs9wOpK4JFpnfhGjU52AOnDRKeICUMXBQDoYeGoApFRbUhPx6YRjyb06o3ThgO/uAW4Psxk+dvHAVNLgMLuwJA84LffBlq8wOYD4Z9z5khg+nCgfy4woAfw7C1AshP48hsjERv3tY8K/PX7Zz7HjsPAty5uf/z3J7dfBoBgCLjvr8CrdwEWw7+DdEL6CEC2iU4RE4b/MfPwA5GxrejeA5UlD4iOEReBEPDnZUCqGxjW+8Ieo6jAu1+0j1yMPWUHb48fuP337SMZuWlnPm5YAbB0OxBSgEWbgaH57df/+mNg4mBgdGFXvxuDyRorOkHMGL4o9LT2FB2BiGJsXn5/1Pb/rugYMfPxhva5As5ZwO8WAIt/DGSd56jqlgPtj3Hc0T4C8P6jwOC8r29/9E3gkgHAtWFWHP7xNYBVBvo9Cry/DvjLPcCeWuCNcuBn1wH3/QUofAS45WWg2ROlbzSR5U4VnSBmDF8Usi3ZcEgO0TGIKMb+3m8kmgtmio4RE5MGAxt/CXz+FHDVUOCWV4C65nM/prhn+2NWPwPcPwW441Vg+1dzFD5cDyzdBrx4jm6V6gbefhDY/zKw4mftJePevwC/uQ14axVQVQfs+h/AbQeeeS9632tCkm1AjnEXAzN8UZAkCXnWvPPfkYgSmyThzUGT4c2ZIDpJ1CU5gaJc4OL+wF++3/5J/y/Lz/0Yu7X9MaP6As99q/1QwkuL2m9buh2orAPS7gGs323/BQA3vghM/MXZn+/1FUCau30EYvkO4LrRgM0K3HxR+2VTyxoLWJNEp4gZq+gA8ZBvzUdlsFJ0DCKKsZAsYc7Qa3HnumbYGjeJjhMzqgb4QxE8Jtj+9Y9nAt+bePrtpT8Gfved9omQ31TfAjzzPrDyyfbLigoElfavg0r7ZVPLvVx0gpgyR1Gw5QNe0SmIKB68VgveGfkdfHv1CVhaq0THOa9WH7C39uvL1fXtZyNkJAOZycCz/wauGQn0SAOOtQK/Xwwcamz/JH/SlF8C148GHryi/fJP3gWmDQMKsoATXuDtz9s/9S96vP323LSzT2AsyAL6dj/z+kfmAD+cDvTKaL88bgAwZyVwRSnw56Xtl03NwPMTAJMUhQxLBpKlZLRqraKjEFEcNNpteL/sXtzwxQuQfXWi45zTuipg0rNfX579Zvvvd1zafgrizsPtEwiPnWgvDmWFQPnP2k+VPKnyaPvtJ9W1AP/xKnCkqX2uwdD89pJweWnn8y3aDOw9Csy5/+vrHrwCWFcNXPQkMKYf8NQNnX9ew7ClGXIjqFNJmqZpokPEw6dtn2JbYJvoGEQUR8Wtbbjyi+cghfghgWIk7zpgwvuiU8SU4ScznlRgKxAdgYjibFdyElaNng3NoAvhkA4YfH4CYKaiYC2AlMCrtxFRZNanZ2Bzgq/eSDrGomAcTtnJbaeJTGp5956oGnL/+e9I1BlJvYGU/qJTxJxpigIA9LNzD3sis/q4YACOFn1bdAwykp7TRSeIC3MVBRuLApGZvVs0Gs35M0THIKPIv0l0grgwVVFIs6QhU84UHYOIRJEkvDl4Crw5l4pOQonOkQV0N+6yzacyVVEAePiByOzaV2+8DsH0oaKjUCLLuxaQLaJTxIXpikKhjXujEpld++qN34WS3Fd0FEpU+TeKThA3pisKOdYcdJPPsz8rERleo92GD0bfC82RLToKJRpbGpAzRXSKuDFdUQA4qkBE7Q66nPik7D+hWZNFR6FE0msmYLGLThE3piwKRbYi0RGISCd2dkvGF6O4eiN1QoF5DjsAJi0Kvay9kCzxEwQRtVubkYEtwx/h6o10ftZkoMeVolPElSmLgiRJKLYXi45BRDqyLKcXqofcJzoG6V3P6YDFKTpFXJmyKADAQMdA0RGISGc+Kijm6o10bgXmWGTpVKYtClmWLGRZskTHICKdebdoNFryzbE0L3WSPQPodY3oFHFn2qIAAAPtHFUgom+QJLw5+HL4uo8TnYT0ps/tgMUhOkXcmbooFNuLufU0EZ0hKEt4c9iNCKaViI5CetLvbtEJhDB1UUiWk5FnzRMdg4h0qM0q4++j7oCa1Ft0FNKD9BFA+nDRKYQwdVEAePiBiMJrsNvwQdn90Bycz2R6hXeJTiCM6YtCf3t/2GGeFbaIqHNqXE4sLnsEmjVJdBQSxeIE+pr3bBjTFwWbZMMgxyDRMYhIx3acXL1RsoqOQiLkXQfY00WnEMb0RQEASh2loiMQkc6tzcjE1uGPiI5BIpj4sAPAogAAyLRkope1l+gYRKRzS3PzUD2YqzeaSlJvIHeq6BRCsSh8haMKRHQhPuw9EHX9bhMdg+Kl7yxAMvdp9CwKXymyFcEluUTHIKIE8E7/MWjJ4+qNhidZgaJ7RKcQjkXhKxbJgiGOIaJjEFEikCS8OeRy+LIvEZ2EYqngJsDNw9IsCqcotZdypUYiuiAnV28MpfEDhmEV/6foBLrAonCKFEsK+tr6io5BRAmizWbB30fOgppUIDoKRVvmRUDWxaJT6AKLwjeMdI4UHYGIEsgxhw3/Hv0AV280Go4mdGBR+IZe1l7oYekhOgYRJZADbicWj/5Prt5oFO789vkJBIBF4axGOUeJjkBECWZHSjd8OfJRrt5oBMWPALJNdArdYFE4i0JbIdJl8y7XSUSRWZOZhW3DOWSd0GypPCXyG1gUzkKSJM5VIKKILMnNx/7B3xcdgyLV/z7A1k10Cl1hUQhjoH0g3JJbdAwiSkAf9B6MY4XfEh2DOku2cxLjWbAohGGVrBjuGC46BhElqLcHXIQTedNEx6DOKJwFuGI3mX3u3LkoLS2Fy+VCZmYmpk6dira2NsyaNQvXXXcdnn76aWRnZyMlJQX33XcfAoFAx2MXLlyI8ePHIy0tDZmZmZgxYwYqKys7bt+3bx8kScI//vEPXHrppXC5XCgrK8Pu3buxdu1ajB49GsnJyZg2bRrq6+s7lZtF4RyGOobCLtlFxyCiBKRJEuYMvhy+7LGio9CFkO3AkCdi9vRHjhzBbbfdhrvuugs7duzA8uXLccMNN0DTNADAkiVLOq5/55138N577+Hpp5/ueHxbWxtmz56NdevWYcmSJZBlGddffz1UVT3tdZ566ik88cQT2LBhA6xWK26//XY89thjeOmll1BeXo69e/fiySef7FR2STuZks7qS++XWO1bLToGESWo5JCCO9b8Bdbm7aKj0Ln0/wFQ9r8xe/oNGzZg1KhR2LdvH3r37n3abbNmzcJHH32EmpoauN3th7xfffVV/OhHP0JzczNk+czP9MeOHUN2dja2bNmCkpIS7Nu3D3379sX//d//4e677wYAvPvuu7jtttuwZMkSTJ48GQDw/PPP429/+xt27tx5wdk5onAeI5wj4JScomMQUYJqtVrwj1F3QnVz9UbdsjiBIT+N6UsMGzYMU6ZMQWlpKW6++Wa89tpraGxsPO32kyUBAMaOHYvW1lbU1NQAAPbs2YPbbrsNhYWFSElJQZ8+fQAABw4cOO11hg4d2vF1Tk4OAKC0tPS06+rq6jqVnUXhPBySg2dAEFGX1Dts+LDsfmj2TNFR6GyK7gPcPWP6EhaLBYsXL8aCBQswePBgvPLKKyguLkZ1dfUFPX7mzJk4fvw4XnvtNaxevRqrV7ePdJ86jwEAbLav13+Qvtoe+5vXffNwxfmwKFyA4Y7h3IKaiLpkv9uFJWWPQLPwbCpdsbiBwT+Oy0tJkoRx48bh6aefRkVFBex2O95//30AwKZNm+D1ejvu++WXXyI5ORn5+floaGjArl278MQTT2DKlCkYNGjQaaMRscaicAFskg2jnaNFxyCiBLctpRtWj57N1Rv1ZMAPAFdOzF9m9erV+OUvf4l169bhwIEDeO+991BfX49BgwYBaB8ZuPvuu7F9+3bMnz8fTz31FB588EHIsoz09HRkZmbiz3/+M/bu3YulS5di9uzZMc98EovCBRrqGIokieu4E1HXrM7IwvZhD4uOQQBgTQYGPRaXl0pJScFnn32G6dOnY8CAAXjiiSfwwgsvYNq09lNop0yZgv79+2PChAm49dZbcc011+DnP/85AECWZbz77rtYv349SkpK8Oijj+I3v/lNXHIDPOuhUzb5NmG5d7noGERkANfv24aCHa+JjmFuQ34KDHtWdArMmjULTU1N+OCDD0RHOSuOKHRCiaMEKXKK6BhEZADv9xmCY4W3iI5hXrZUYNB/iU6REFgUOsEiWTDONU50DCIyiLcHjMWJXleKjmFOQ34K2Ln534XgoYcI/PPEP3E4dFh0DCIyAJui4u4Nf4fjGBd2i5vkIuDqbYCFK+9eCI4oRGCCa4LoCERkEEGLjDdH3IJQ6mDRUcxj5AssCZ3AohCBHGsOBtoHio5BRAbRarXgn6PuhOrOFx3F+HKvAPKuEZ0iobAoRGicaxys4LnQRBQddQ4bPhr9ADR7hugoxiVZgVG/E50i4bAoRChZTsYo5yjRMYjIQPYlubB09CPQLFwJNib63w/wEE+nsSh0wSjnKCRLyaJjEJGBbE1NwdpRs6FJFtFRjMWRCQx9+vz3ozOwKHSBTbJhvHu86BhEZDBfZGZjB1dvjK7SZ3g6ZIRYFLqo2F6M3tbe578jEVEnLO7RGzWDvic6hjGklQJF94pOkbBYFKJgknsSJzYSUdS916cEDX1vFh0j8Y16GZB5KCdSLApRkGpJxRjnGNExiMiA3iq+BK09LxcdI3H1uxvImSg6RUJjUYiSkc6RyJQzRccgIoPRJAlzSqbBn8UPI53m6gmMeEF0ioTHohAlFsmCKUlTRMcgIgMKWGS8NeIWhFK40FunlP0BsKeKTpHwWBSiqIe1B0rsJaJjEJEBnbBa8c9Rd0F154mOkhgKbgHyrhWdwhBYFKJsvGs83JJbdAwiMqA6px0fj/4BNJ7md26OTGD0K6JTGAaLQpQ5ZAcmuyeLjkFEBlXdsXqjU3QU/Rr5IuDsLjqFYbAoxEA/ez9uGkVEMbM1NRVrR3L1xrPqOR3o+x3RKQyFRSFGJromcnlnIoqZL7K6Y9fQh0TH0BdrN6DsVdEpDIdFIUYcsoNnQRBRTC3q2QcHB94tOoZ+jPg1kMStuqONRSGG+tj6oNReKjoGERnYv/qWoqHvTaJjiNdzBtD/PtEpDIlFIcYudV+KNDlNdAwiMrC3i8ehredU0THEcfUALn5ddArDYlGIMZtkw5VJV0LmHzURxYgqSZhTMh3+rDLRUeJPkoGxbwLOLNFJDIvvXnGQa83FRc6LRMcgIgPzW2S8NeJWhFKKRUeJr0GPAbk8JT2WWBTipMxZhgJrgegYRGRgJ6xWzB11N1RXT9FR4iPzYmDo/yc6heGxKMSJJEm4MulKJElJoqMQkYEdddoxr+xBaLY00VFiy5YKjHsHkK2ikxgei0IcuWU3rkq6ChIk0VGIyMCqktxYXvaosVdvLHsVSO4jOoUpsCjEWZ4tDxc7LxYdg4gMbnNqKtaPnA1NMuB/84V3An2+JTqFaRjwb5D+cb4CEcXDqqzu2FX6sOgY0ZVSzA2f4oxFQQDOVyCieFnUqw8OFd8pOkZ02FKASz8ArPy/M55YFARxy25MS5rG9RWIKObmFg7D8T43iI7RNZIMXPIWkMoN9+KN71IC9bL1wgTXBNExiMgE3hp4Kdp6JPD+M6XPAL1miE5hSiwKgg1zDuN+EEQUc6okYU7p1QhkjhIdpfMKbgZK/lt0CtNiUdCBy9yXoZe1l+gYRGRwfouMt0fcDqVbf9FRLlzaMO7jIBiLgg5YJAuuTroaKXKK6ChEZHDNNgvmlt0D1dVDdJTzc2QBEz7g5EXBWBR0wiW7MDN5JmywiY5CRAZX67BjftlD0GypoqOEJ1mB8f/goko6wKKgI1mWLFyRdIXoGERkApVJbqwY/Sg02SE6ytmN/C2QM0l0CgKLgu4U2Ysw1jlWdAwiMoFNaWnYoMfVG4u+DxQ/JDoFfUVnfzsIAMa4xqDEXiI6BhGZwMrsHOwpfVB0jK/lXQuM/oPoFHQKFgWdmuSehEJboegYRGQCC3oV4vCAWaJjANnjgEveAWSL6CR0ChYFnZIlGdOSpqGHJQFmJhNRwvtnv+Fo7H2duACpQ4DLPgKsLnEZ6KxYFHTMKllxTfI1SJfTRUchIhN4a+Bl8PQQMIHQnQdMWgjY+X+dHrEo6JxTduK65Ou4gRQRxZwiS5hTOjO+qzfa04FJi9rLAukSi0ICSLGk4Nrka2GHXXQUIjI4n0XG2yNui8/qjRZX++GG1MGxfy2KGItCgsi2ZmNm8kxYYRUdhYgMrtlmxdzR34PqzI3di0gWYNw77RMYSddYFBJIni0PM5NnwgLOCCai2Kp1OrBgzMMxWr1RAspebT8VknSPRSHBFNgKMCN5BssCEcXc3iQ3Pov66o0SUPYHoOh7UXxOiiUWhQTUx9YH05KmQeaPj4hibGNaGipGPhql1Ru/Kgn974vCc1G88J0mQfWz98NVSVdBgiQ6ChEZXHl2LvaW/KCLzyIBZX9kSUhALAoJrL+9P65IuoJlgYhibn5ePxwZcEeEjz5ZEu6NaiaKDxaFBDfQPhBT3VNZFogo5v7RbwSaend2AqIEjHmVJSGBsSgYwGDHYFyVdBXnLBBRzL05cCI8uRMv8N5flYSi78cyEsUY31kMYoB9AM+GIKKYU2QJb5Zeg0DGiPPckyXBKFgUDKSvrS+uS76OKzgSUUx5rTLeGfkdKN2Kzn4HyQJc9BpLgkGwKBhMni0P13e7Hk7JKToKERlYk82C90Z//8zVG2UHMP4fQL+7xQSjqGNRMKBcay5u7HYj3JJbdBQiMrDDTjsWlj0EzZbSfoW1GzBpAZB/g9hgFFWSpmma6BAUG01KE95vfR8taovoKERkYCOaGnHppr9AmvBvIGOk6DgUZSwKBtemtuHD1g9Rp9SJjkJEBpUqp+JG9wx0s2WJjkIxwKJgAkEtiAVtC1AdrBYdhYgMJseSg2uSr4Fb5qFOo2JRMAlN07DCuwKb/JtERyEig+hj64PpSdNhk2yio1AMsSiYTIWvAuXecmjgj52IIjfMMQwTXBMgR2WzKNIzFgUTqgxUYmHbQoQQEh2FiBKMDBkT3RNR6igVHYXihEXBpGpDtfio9SN4NI/oKESUIFySC9OTpiPPlic6CsURi4KJtaqtmN86H0eUI6KjEJHOZVoyMTNpJlItqaKjUJyxKJicoilY7lmOrYGtoqMQkU4V2gpxZdKVsEtcHt6MWBQIALDVvxXLPcuhQBEdhYh0ZLRzNC5xXgJJ4lb2ZsWiQB1qQ7WY1zoPrVqr6ChEJJhDcuBy9+XoZ+8nOgoJxqJAp/GoHsxvm49DoUOioxCRIN0t3TE9aTrnIxAAFgU6C1VTscq7Chv8G0RHIaI4G+YYhktdl8IiWURHIZ1gUaCwqoPVWNy2GF7NKzoKEcWYHXZMTZqK/vb+oqOQzrAo0Dm1qq1Y1LYIB0MHRUchohjJsmRhetJ0pFvSRUchHWJRoPPSNA1rfWux2rcaKlTRcYgoioY5hmG8azysklV0FNIpFgW6YLWhWixsW4hmtVl0FCLqomQpGVOTpqK3rbfoKKRzLArUKQEtgOWe5dgR2CE6ChFFqNhejEmuSXDIDtFRKAGwKFBEqoPVWNq2lGsuECUQp+TEJPckDLAPEB2FEgiLAkXMr/nxmeczbA9sFx2FiM6jt7U3piZNRbKcLDoKJRgWBeqyfcF9WNK2hKMLRDpkl+wY7xrPbaEpYiwKFBV+zY9yTzm2BbaJjkJEXymyFWGieyKS5CTRUSiBsShQVO0P7sdSz1K0qC2ioxCZVje5Gya6JqLQXig6ChkAiwJFXUgLYa1vLdb71nM3SqI4kiBhmGMYxrrGcktoihoWBYqZJqUJyz3LsT+0X3QUIsPLtmRjinsKcqw5oqOQwbAoUMztDezFCs8KTnYkigGn5MRFzosw1DEUsiSLjkMGxKJAcRHUgljjW4MNvg1cBpooCmTIKHWU4mLnxXDKTtFxyMBYFCiuGpVGrPSuRFWwSnQUooTV29obE9wTkGHJEB2FTIBFgYQ4FDqElZ6VqFVqRUchShjpcjomuCegj62P6ChkIiwKJNSewB6s8q7iRlNE5+CSXBjjHMN5CCQEiwIJp2gKtvi3YI1vDbyaV3QcIt2wS3aMdIzECOcInu5IwrAokG74NT82+DZgo28jAgiIjkMkjA02DHMOwyjHKE5UJOFYFEh3fKoPFf4KbPRvREBjYSDzsMCCUkcpypxlcMtu0XGIALAokI75NT82+jaiwl8Bv+YXHYcoZiywYLB9MMa4xnB3R9IdFgXSPb/mxybfJlT4K+DTfKLjEEWNHXaUOkox3DmcBYF0i0WBEkZAC2CzfzM2+TZxlUdKaG7JjeHO4RjqGAqH5BAdh+icWBQo4Siagj3BPajwVaBOqRMdh+iCpclpGOUchYH2gbBKVtFxiC4IiwIltEOhQ6jwVaAqWAUN/KtM+tTD0gMjnCNQZCuCJEmi4xB1CosCGUKz0oyN/o3Y7t/OUytJF6ywYoB9AIY5hqG7tbvoOEQRY1EgQ/FrfuwK7MI2/zYeliAh0uQ0lDhKMMQ+hGsgkCGwKJBh1YXqsDWwFbsCu7geA8WUDBmFtkKUOkqRb83n4QUyFBYFMrygFsSewB5sC2zD4dBh0XHIQLpbumOQfRAG2AdwgSQyLBYFMpXjynHsCOzA7sButKgtouNQAuomd0OxvRiD7IO4zTOZAosCmVZtqBa7AruwJ7AHbVqb6DikY3bYUWQvwiD7IPSy9uKhBTIVFgUyPU3TcCh0CLsDu7E3uJc7WBIAwCE5UGgrRD9bP/S29ea6B2RaLApEp1A1FTWhGlQGK1EdqOYKkCaTJCWhn70f+tn6Ic+aB1mSRUciEo5Fgegc6kJ1qApWoTpYzdMtDSpdTkehrRBF9iLkWHJ4WIHoG1gUiC5Qm9qG/cH92BfchwOhA9zRMkG5JBfyrfkosBWgwFaAbnI30ZGIdI1FgSgCmqahXqnHwdBBHAodwqHQIRYHnbLAgh7WHiiwFaC3tTeyLdkcNSDqBBYFoig4tTicLA9c5EkMh+RAriUXPaw9On7ZJJvoWEQJi0WBKAY0TUOD2oCjoaM4qhzF0dBRNCgNUKCIjmY46XL6aaUgQ87giAFRFLEoEMWJoimoV+pxNHQUdUodjoaOolFthApVdLSEYIEFGZYMZFmyOn51t3TnfgpEMcaiQCSQoiloVpvRoDSgUWls/11tRKPSiBBCouMJIUNGN7kb0uV0ZFoykW3NRpYlC+lyOk9XJBKARYFIhzRNQ4vaguPqcbQoLTihnkCL2v77CfVEwq8kaYMNKZYUpMlpSJVTkWpJRaqcijQ5Dd3kbiwERDrCokCUgBRN6SgNJ9QT8Gpe+DQfvGr779/8OtaHNyRIsEt2OCQHHJIDbskNt+xGkpwEt/SN32U3HJIjpnmIKHpYFIhMwK/5EdJCUDQFIYQQ0kIdvytQOm6D1P6mL6P9E/1pX0vtX1slK+ywwypZYZNssEt22CW7yG+PiGKIRYGIiIjC4oFAIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgoLBYFIiIiCotFgYiIiMJiUSAiIqKwWBSIiIgorP8fI6aCDPLjmfIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_tr 分布 - 饼图\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set_palette(['lightgreen', 'orange'])\n",
    "df_tr['label'].value_counts().plot(kind='pie', labels=['ham', 'spam'], autopct='%0.2f%%')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 长度分布图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_tr_len = df_tr['content'].apply(lambda x: len(x))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('all')\n",
    "sns.histplot(df_tr_len, color='blue', label='content', bins=500, kde=True)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('spam')\n",
    "sns.histplot(df_tr_len[df_tr['label']=='spam'], color='red', bins=100, kde=True)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('ham')\n",
    "sns.histplot(df_tr_len[df_tr['label']=='ham'], color='green', bins=300, kde=True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1700177979024,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "MHQernlHVVTe",
    "outputId": "bd4740a9-2848-44fa-e5e5-7489a306aca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3537.000000\n",
      "mean       81.278202\n",
      "std        62.323330\n",
      "min         2.000000\n",
      "0%          2.000000\n",
      "5%         22.000000\n",
      "10%        25.000000\n",
      "15%        28.000000\n",
      "20%        32.000000\n",
      "25%        35.000000\n",
      "30%        39.000000\n",
      "35%        44.000000\n",
      "40%        49.000000\n",
      "45%        54.000000\n",
      "50%        61.000000\n",
      "55%        70.000000\n",
      "60%        80.000000\n",
      "65%        92.000000\n",
      "70%       108.000000\n",
      "75%       124.000000\n",
      "80%       139.000000\n",
      "85%       149.000000\n",
      "90%       156.000000\n",
      "95%       161.000000\n",
      "max       910.000000\n",
      "Name: content, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 查看总长度分布数据\n",
    "print(df_tr_len.describe(percentiles=[i*0.05 for i in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3537.000000\n",
      "mean       81.278202\n",
      "std        62.323330\n",
      "min         2.000000\n",
      "50%        61.000000\n",
      "90%       156.000000\n",
      "91%       157.000000\n",
      "92%       158.000000\n",
      "93%       159.000000\n",
      "94%       160.000000\n",
      "95%       161.000000\n",
      "96%       165.000000\n",
      "97%       174.000000\n",
      "98%       195.000000\n",
      "99%       284.840000\n",
      "max       910.000000\n",
      "Name: content, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 查看尾部长度分布\n",
    "print(df_tr_len.describe(percentiles=[0.9+i*0.01 for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQhLFuDUV2_u"
   },
   "source": [
    "## 3. 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 sklearn 中，共有五种朴素贝叶斯算法：\n",
    "\n",
    "##### 1. BernoulliNB - 伯努利朴素贝叶斯\n",
    "模型适用于多元伯努利分布，即每个特征都是二值变量，如果不是二值变量，该模型可以先对变量进行二值化。\n",
    "\n",
    "在文档分类中特征是单词是否出现，如果该单词在某文件中出现了即为1，否则为0。\n",
    "\n",
    "在文本分类中，统计词语是否出现的向量(word occurrence vectors)(而非统计词语出现次数的向量(word count vectors))可以用于训练和使用这个分类器。\n",
    "\n",
    "BernoulliNB 可能在一些数据集上表现得更好，特别是那些更短的文档。如果时间允许，建议对两个模型都进行评估。\n",
    "\n",
    "---\n",
    "##### 2. CategoricalNB - 类朴素贝叶斯\n",
    "对分类分布的数据实施分类朴素贝叶斯算法，专用于离散数据集， 它假定由索引描述的每个特征都有其自己的分类分布。\n",
    "\n",
    "对于训练集中的每个特征 X，CNB 估计以类 y 为条件的 X 的每个特征 i 的分类分布。\n",
    "\n",
    "样本的索引集定义为 J = 1, …, m，其中 m 为样本数。\n",
    "\n",
    "---\n",
    "##### 3. GaussianNB - 高斯朴素贝叶斯\n",
    "特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。这种模型假设特征符合高斯分布。\n",
    "\n",
    "---\n",
    "##### 4. MultinomialNB - 多项式朴素贝叶斯\n",
    "特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。\n",
    "\n",
    "不支持负数，所以输入变量特征的时候，不用 `StandardScaler` 进行标准化数据，可以使用 `MinMaxScaler` 进行归一化。\n",
    "\n",
    "这个模型假设特征复合多项式分布，是一种非常典型的文本分类模型，模型内部带有平滑参数 `alpha`。\n",
    "\n",
    "---\n",
    "##### 5. ComplementNB - 补充朴素贝叶斯\n",
    "是 MultinomialNB 模型的一个变种，实现了补码朴素贝叶斯(CNB)算法。\n",
    "\n",
    "CNB 是标准多项式朴素贝叶斯(MNB)算法的一种改进，比较适用于不平衡的数据集，在文本分类上的结果通常比 MultinomialNB 模型好。\n",
    "\n",
    "具体来说，CNB 使用来自每个类的补数的统计数据来计算模型的权重。\n",
    "\n",
    "CNB 的发明者的研究表明，CNB 的参数估计比 MNB 的参数估计更稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论上来说，MultinomialNB 和 ComplementNB 的表现应该是最好的。这五种算法我们都会进行探索。\n",
    "\n",
    "篇幅有限，贝叶斯分类算法中，我们都将默认使用 Optuna 进行超参数调优，不再对比无调优情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从头加载数据，避免未执行前面的单元\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "# 检测编码\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "# 原文件并非 utf-8 编码格式\n",
    "df_tr = pd.read_csv('train.csv', encoding=detect_encoding('train.csv'))             # df_train\n",
    "df_te = pd.read_csv('test.csv', encoding=detect_encoding('test.csv'), header=None)  # df_test\n",
    "\n",
    "# 将每行的第三列之后的内容合并到第三列\n",
    "df_tr['v2'] = df_tr.apply(lambda row: ','.join(map(str, filter(lambda x: pd.notna(x), row[2:]))), axis=1)\n",
    "df_tr = df_tr.iloc[:, :3]\n",
    "\n",
    "# 规范命名\n",
    "df_tr = df_tr[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'content'})\n",
    "df_te = df_te[[0]].rename(columns={0: 'content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3537,), (3537,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据划分\n",
    "x = df_tr['content']                                            # 内容\n",
    "y = df_tr['label'].apply(lambda x: 1 if x == 'spam' else 0)     # 标签\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2829,), (708,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集和验证集\n",
    "# 8 : 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3407)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2035,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要预测的真实测试集\n",
    "real_x = df_te['content']\n",
    "real_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用于将文本数据转换为词袋模型的表示形式，即将文本转换为词频矩阵\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x_train_cnt = cv.fit_transform(x_train.values)\n",
    "x_test_cnt = cv.transform(x_test.values)\n",
    "real_x_cnt = cv.transform(real_x.values)\n",
    "\n",
    "x_train_cnt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna.logging\n",
    "\n",
    "# 设置 Optuna 的日志级别为 WARNING，即 WARNING 以上才输出\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2.1 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.04664517822569222\n",
      "Best test value:  0.9901129943502824\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1.0)\n",
    "    model = BernoulliNB(alpha=alpha)\n",
    "    model.fit(x_train_cnt, y_train)\n",
    "    return model.score(x_test_cnt, y_test)\n",
    "\n",
    "# 创建Optuna优化对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# 输出最佳超参数取值\n",
    "best_alpha = study.best_params['alpha']\n",
    "best_test_value = study.best_value\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best test value: \", best_test_value)\n",
    "\n",
    "# 用最佳超参数训练并预测\n",
    "best_mnb = BernoulliNB(alpha=best_alpha)\n",
    "best_mnb.fit(x_train_cnt, y_train)\n",
    "mnb_pred = best_mnb.predict(real_x_cnt)\n",
    "\n",
    "# 输出\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2.2 CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1.0)\n",
    "    model = CategoricalNB(alpha=alpha)\n",
    "    model.fit(x_train_cnt.toarray(), y_train)\n",
    "    return model.score(x_test_cnt.toarray(), y_test)\n",
    "\n",
    "# 创建Optuna优化对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# 输出最佳超参数取值\n",
    "best_alpha = study.best_params['alpha']\n",
    "best_test_value = study.best_value\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best test value: \", best_test_value)\n",
    "\n",
    "# 用最佳超参数训练并预测\n",
    "best_mnb = CategoricalNB(alpha=best_alpha)\n",
    "best_mnb.fit(x_train_cnt.toarray(), y_train)\n",
    "mnb_pred = best_mnb.predict(real_x_cnt.toarray())\n",
    "\n",
    "# 输出\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2.3 GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best var_smoothing: 0.3163251169367887\n",
      "Best test value:  0.9901129943502824\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    var_smoothing = trial.suggest_float('var_smoothing', 1e-10, 1.0)\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    model.fit(x_train_cnt.toarray(), y_train)\n",
    "    return model.score(x_test_cnt.toarray(), y_test)\n",
    "\n",
    "# 创建Optuna优化对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 输出最佳超参数取值\n",
    "best_var_smoothing = study.best_params['var_smoothing']\n",
    "best_test_value = study.best_value\n",
    "print(\"Best var_smoothing:\", best_alpha)\n",
    "print(\"Best test value: \", best_test_value)\n",
    "\n",
    "# 用最佳超参数训练并预测\n",
    "best_mnb = GaussianNB(var_smoothing=best_var_smoothing)\n",
    "best_mnb.fit(x_train_cnt.toarray(), y_train)\n",
    "mnb_pred = best_mnb.predict(real_x_cnt.toarray())\n",
    "\n",
    "# 输出\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2.4 MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.7932421694220678\n",
      "Best test value:  0.9887005649717514\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1.0)\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(x_train_cnt, y_train)\n",
    "    return model.score(x_test_cnt, y_test)\n",
    "\n",
    "# 创建Optuna优化对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# 输出最佳超参数取值\n",
    "best_alpha = study.best_params['alpha']\n",
    "best_test_value = study.best_value\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best test value: \", best_test_value)\n",
    "\n",
    "# 用最佳超参数训练并预测\n",
    "best_mnb = MultinomialNB(alpha=best_alpha)\n",
    "best_mnb.fit(x_train_cnt, y_train)\n",
    "mnb_pred = best_mnb.predict(real_x_cnt)\n",
    "\n",
    "# 输出\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2.5 ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.25508267533275286\n",
      "Best test value:  0.9901129943502824\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1.0)\n",
    "    model = ComplementNB(alpha=alpha)\n",
    "    model.fit(x_train_cnt, y_train)\n",
    "    return model.score(x_test_cnt, y_test)\n",
    "\n",
    "# 创建Optuna优化对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# 输出最佳超参数取值\n",
    "best_alpha = study.best_params['alpha']\n",
    "best_test_value = study.best_value\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best test value: \", best_test_value)\n",
    "\n",
    "# 用最佳超参数训练并预测\n",
    "best_mnb = ComplementNB(alpha=best_alpha)\n",
    "best_mnb.fit(x_train_cnt, y_train)\n",
    "mnb_pred = best_mnb.predict(real_x_cnt)\n",
    "\n",
    "# 输出\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.1 数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# 从头加载数据，避免未执行前面的单元\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "# 检测编码\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "# 原文件并非 utf-8 编码格式\n",
    "df_tr = pd.read_csv('train.csv', encoding=detect_encoding('train.csv'))             # df_train\n",
    "df_te = pd.read_csv('test.csv', encoding=detect_encoding('test.csv'), header=None)  # df_test\n",
    "\n",
    "# 将每行的第三列之后的内容合并到第三列\n",
    "df_tr['v2'] = df_tr.apply(lambda row: ','.join(map(str, filter(lambda x: pd.notna(x), row[2:]))), axis=1)\n",
    "df_tr = df_tr.iloc[:, :3]\n",
    "\n",
    "# 规范命名\n",
    "df_tr = df_tr[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'content'})\n",
    "df_te = df_te[[0]].rename(columns={0: 'content'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:30.813921200Z",
     "start_time": "2023-12-09T05:11:29.007157900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 数据预处理\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_tr['content'], df_tr['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用CountVectorizer将文本转换为词袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "\n",
    "# 转换为PyTorch Tensor\n",
    "X_train_tensor = torch.tensor(X_train_vec.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.map({'ham': 0, 'spam': 1}).values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_vec.toarray(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.map({'ham': 0, 'spam': 1}).values, dtype=torch.float32)\n",
    "\n",
    "# 定义数据集类\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = SpamDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:30.932495400Z",
     "start_time": "2023-12-09T05:11:30.816852700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "class SpamClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x.unsqueeze(1))  # 添加一个维度\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:30.951255100Z",
     "start_time": "2023-12-09T05:11:30.932495400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "model = SpamClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:30.966867200Z",
     "start_time": "2023-12-09T05:11:30.940507300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1/10:   9%|▉         | 4/45 [00:00<00:01, 33.91it/s]\u001B[A\n",
      "Epoch 1/10:  20%|██        | 9/45 [00:00<00:00, 37.83it/s]\u001B[A\n",
      "Epoch 1/10:  29%|██▉       | 13/45 [00:00<00:00, 37.86it/s]\u001B[A\n",
      "Epoch 1/10:  40%|████      | 18/45 [00:00<00:00, 38.62it/s]\u001B[A\n",
      "Epoch 1/10:  51%|█████     | 23/45 [00:00<00:00, 39.56it/s]\u001B[A\n",
      "Epoch 1/10:  62%|██████▏   | 28/45 [00:00<00:00, 40.04it/s]\u001B[A\n",
      "Epoch 1/10:  73%|███████▎  | 33/45 [00:00<00:00, 40.44it/s]\u001B[A\n",
      "Epoch 1/10:  84%|████████▍ | 38/45 [00:00<00:00, 40.46it/s]\u001B[A\n",
      "Epoch 1/10: 100%|██████████| 45/45 [00:01<00:00, 39.75it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.532495645682017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2/10:  11%|█         | 5/45 [00:00<00:00, 42.64it/s]\u001B[A\n",
      "Epoch 2/10:  22%|██▏       | 10/45 [00:00<00:00, 41.03it/s]\u001B[A\n",
      "Epoch 2/10:  33%|███▎      | 15/45 [00:00<00:00, 40.25it/s]\u001B[A\n",
      "Epoch 2/10:  44%|████▍     | 20/45 [00:00<00:00, 40.17it/s]\u001B[A\n",
      "Epoch 2/10:  56%|█████▌    | 25/45 [00:00<00:00, 39.87it/s]\u001B[A\n",
      "Epoch 2/10:  64%|██████▍   | 29/45 [00:00<00:00, 39.65it/s]\u001B[A\n",
      "Epoch 2/10:  73%|███████▎  | 33/45 [00:00<00:00, 39.57it/s]\u001B[A\n",
      "Epoch 2/10:  82%|████████▏ | 37/45 [00:00<00:00, 39.51it/s]\u001B[A\n",
      "Epoch 2/10: 100%|██████████| 45/45 [00:01<00:00, 40.15it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.237653453151385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3/10:  11%|█         | 5/45 [00:00<00:00, 40.29it/s]\u001B[A\n",
      "Epoch 3/10:  22%|██▏       | 10/45 [00:00<00:00, 41.05it/s]\u001B[A\n",
      "Epoch 3/10:  33%|███▎      | 15/45 [00:00<00:00, 41.00it/s]\u001B[A\n",
      "Epoch 3/10:  44%|████▍     | 20/45 [00:00<00:00, 41.17it/s]\u001B[A\n",
      "Epoch 3/10:  56%|█████▌    | 25/45 [00:00<00:00, 41.41it/s]\u001B[A\n",
      "Epoch 3/10:  67%|██████▋   | 30/45 [00:00<00:00, 41.25it/s]\u001B[A\n",
      "Epoch 3/10:  78%|███████▊  | 35/45 [00:00<00:00, 41.08it/s]\u001B[A\n",
      "Epoch 3/10:  89%|████████▉ | 40/45 [00:00<00:00, 40.50it/s]\u001B[A\n",
      "Epoch 3/10: 100%|██████████| 45/45 [00:01<00:00, 40.88it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.09333996238807837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4/10:  11%|█         | 5/45 [00:00<00:00, 40.90it/s]\u001B[A\n",
      "Epoch 4/10:  22%|██▏       | 10/45 [00:00<00:00, 41.00it/s]\u001B[A\n",
      "Epoch 4/10:  33%|███▎      | 15/45 [00:00<00:00, 40.48it/s]\u001B[A\n",
      "Epoch 4/10:  44%|████▍     | 20/45 [00:00<00:00, 40.43it/s]\u001B[A\n",
      "Epoch 4/10:  56%|█████▌    | 25/45 [00:00<00:00, 40.23it/s]\u001B[A\n",
      "Epoch 4/10:  67%|██████▋   | 30/45 [00:00<00:00, 39.93it/s]\u001B[A\n",
      "Epoch 4/10:  78%|███████▊  | 35/45 [00:00<00:00, 40.35it/s]\u001B[A\n",
      "Epoch 4/10:  89%|████████▉ | 40/45 [00:00<00:00, 40.33it/s]\u001B[A\n",
      "Epoch 4/10: 100%|██████████| 45/45 [00:01<00:00, 40.29it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.04695290985206763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5/10:   9%|▉         | 4/45 [00:00<00:01, 39.73it/s]\u001B[A\n",
      "Epoch 5/10:  20%|██        | 9/45 [00:00<00:00, 40.57it/s]\u001B[A\n",
      "Epoch 5/10:  31%|███       | 14/45 [00:00<00:00, 40.74it/s]\u001B[A\n",
      "Epoch 5/10:  42%|████▏     | 19/45 [00:00<00:00, 40.42it/s]\u001B[A\n",
      "Epoch 5/10:  53%|█████▎    | 24/45 [00:00<00:00, 39.99it/s]\u001B[A\n",
      "Epoch 5/10:  62%|██████▏   | 28/45 [00:00<00:00, 39.92it/s]\u001B[A\n",
      "Epoch 5/10:  73%|███████▎  | 33/45 [00:00<00:00, 40.04it/s]\u001B[A\n",
      "Epoch 5/10:  84%|████████▍ | 38/45 [00:00<00:00, 40.02it/s]\u001B[A\n",
      "Epoch 5/10: 100%|██████████| 45/45 [00:01<00:00, 40.04it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.02688459021349748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6/10:  11%|█         | 5/45 [00:00<00:00, 41.94it/s]\u001B[A\n",
      "Epoch 6/10:  22%|██▏       | 10/45 [00:00<00:00, 40.20it/s]\u001B[A\n",
      "Epoch 6/10:  33%|███▎      | 15/45 [00:00<00:00, 39.67it/s]\u001B[A\n",
      "Epoch 6/10:  42%|████▏     | 19/45 [00:00<00:00, 39.25it/s]\u001B[A\n",
      "Epoch 6/10:  51%|█████     | 23/45 [00:00<00:00, 39.41it/s]\u001B[A\n",
      "Epoch 6/10:  62%|██████▏   | 28/45 [00:00<00:00, 39.72it/s]\u001B[A\n",
      "Epoch 6/10:  73%|███████▎  | 33/45 [00:00<00:00, 40.30it/s]\u001B[A\n",
      "Epoch 6/10:  84%|████████▍ | 38/45 [00:00<00:00, 40.29it/s]\u001B[A\n",
      "Epoch 6/10: 100%|██████████| 45/45 [00:01<00:00, 40.11it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.015931633156206874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7/10:   9%|▉         | 4/45 [00:00<00:01, 39.54it/s]\u001B[A\n",
      "Epoch 7/10:  20%|██        | 9/45 [00:00<00:00, 40.78it/s]\u001B[A\n",
      "Epoch 7/10:  31%|███       | 14/45 [00:00<00:00, 40.01it/s]\u001B[A\n",
      "Epoch 7/10:  42%|████▏     | 19/45 [00:00<00:00, 40.69it/s]\u001B[A\n",
      "Epoch 7/10:  53%|█████▎    | 24/45 [00:00<00:00, 40.72it/s]\u001B[A\n",
      "Epoch 7/10:  64%|██████▍   | 29/45 [00:00<00:00, 40.24it/s]\u001B[A\n",
      "Epoch 7/10:  76%|███████▌  | 34/45 [00:00<00:00, 40.22it/s]\u001B[A\n",
      "Epoch 7/10:  87%|████████▋ | 39/45 [00:00<00:00, 40.53it/s]\u001B[A\n",
      "Epoch 7/10: 100%|██████████| 45/45 [00:01<00:00, 40.55it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.00993757338470055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8/10:  11%|█         | 5/45 [00:00<00:00, 40.29it/s]\u001B[A\n",
      "Epoch 8/10:  22%|██▏       | 10/45 [00:00<00:00, 40.64it/s]\u001B[A\n",
      "Epoch 8/10:  33%|███▎      | 15/45 [00:00<00:00, 41.06it/s]\u001B[A\n",
      "Epoch 8/10:  44%|████▍     | 20/45 [00:00<00:00, 40.79it/s]\u001B[A\n",
      "Epoch 8/10:  56%|█████▌    | 25/45 [00:00<00:00, 40.61it/s]\u001B[A\n",
      "Epoch 8/10:  67%|██████▋   | 30/45 [00:00<00:00, 40.61it/s]\u001B[A\n",
      "Epoch 8/10:  78%|███████▊  | 35/45 [00:00<00:00, 40.18it/s]\u001B[A\n",
      "Epoch 8/10:  89%|████████▉ | 40/45 [00:00<00:00, 40.31it/s]\u001B[A\n",
      "Epoch 8/10: 100%|██████████| 45/45 [00:01<00:00, 40.08it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.007307203729740448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9/10:  11%|█         | 5/45 [00:00<00:00, 40.41it/s]\u001B[A\n",
      "Epoch 9/10:  22%|██▏       | 10/45 [00:00<00:00, 40.53it/s]\u001B[A\n",
      "Epoch 9/10:  33%|███▎      | 15/45 [00:00<00:00, 40.25it/s]\u001B[A\n",
      "Epoch 9/10:  44%|████▍     | 20/45 [00:00<00:00, 39.59it/s]\u001B[A\n",
      "Epoch 9/10:  53%|█████▎    | 24/45 [00:00<00:00, 38.14it/s]\u001B[A\n",
      "Epoch 9/10:  62%|██████▏   | 28/45 [00:00<00:00, 38.12it/s]\u001B[A\n",
      "Epoch 9/10:  71%|███████   | 32/45 [00:00<00:00, 38.60it/s]\u001B[A\n",
      "Epoch 9/10:  82%|████████▏ | 37/45 [00:00<00:00, 39.22it/s]\u001B[A\n",
      "Epoch 9/10: 100%|██████████| 45/45 [00:01<00:00, 39.49it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.004791276829524173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10:   0%|          | 0/45 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 10/10:  11%|█         | 5/45 [00:00<00:00, 40.43it/s]\u001B[A\n",
      "Epoch 10/10:  22%|██▏       | 10/45 [00:00<00:00, 40.16it/s]\u001B[A\n",
      "Epoch 10/10:  33%|███▎      | 15/45 [00:00<00:00, 39.65it/s]\u001B[A\n",
      "Epoch 10/10:  42%|████▏     | 19/45 [00:00<00:00, 39.70it/s]\u001B[A\n",
      "Epoch 10/10:  53%|█████▎    | 24/45 [00:00<00:00, 39.92it/s]\u001B[A\n",
      "Epoch 10/10:  64%|██████▍   | 29/45 [00:00<00:00, 40.27it/s]\u001B[A\n",
      "Epoch 10/10:  76%|███████▌  | 34/45 [00:00<00:00, 40.60it/s]\u001B[A\n",
      "Epoch 10/10:  87%|████████▋ | 39/45 [00:00<00:00, 40.44it/s]\u001B[A\n",
      "Epoch 10/10: 100%|██████████| 45/45 [00:01<00:00, 40.49it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0036608873271486825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:42.378203600Z",
     "start_time": "2023-12-09T05:11:31.129075800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.09964179992675781, Accuracy: 0.9788135593220338\n"
     ]
    }
   ],
   "source": [
    "# 在验证集上评估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_output = model(X_val_tensor)\n",
    "    val_loss = criterion(val_output.squeeze(), y_val_tensor)\n",
    "    val_preds = (val_output.squeeze() >= 0.5).float()\n",
    "    accuracy = torch.sum(val_preds == y_val_tensor).item() / len(y_val_tensor)\n",
    "\n",
    "print(f'Validation Loss: {val_loss.item()}, Accuracy: {accuracy}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:11:42.520422700Z",
     "start_time": "2023-12-09T05:11:42.353773300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 optuna调优"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-09 13:11:42,432] A new study created in memory with name: no-name-e4622bb3-b9ff-4518-9e36-f4576fccb3d4\n",
      "C:\\Users\\99702\\AppData\\Local\\Temp\\ipykernel_7956\\4180536850.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "[I 2023-12-09 13:11:47,858] Trial 0 finished with value: 0.8742937853107344 and parameters: {'hidden_size': 109, 'learning_rate': 1.1996277208846616e-05}. Best is trial 0 with value: 0.8742937853107344.\n",
      "[I 2023-12-09 13:11:53,705] Trial 1 finished with value: 0.9774011299435028 and parameters: {'hidden_size': 137, 'learning_rate': 0.005965976500581366}. Best is trial 1 with value: 0.9774011299435028.\n",
      "[I 2023-12-09 13:11:57,964] Trial 2 finished with value: 0.8912429378531074 and parameters: {'hidden_size': 97, 'learning_rate': 3.33018300793684e-05}. Best is trial 1 with value: 0.9774011299435028.\n",
      "[I 2023-12-09 13:12:03,495] Trial 3 finished with value: 0.9096045197740112 and parameters: {'hidden_size': 128, 'learning_rate': 0.00013184474836690105}. Best is trial 1 with value: 0.9774011299435028.\n",
      "[I 2023-12-09 13:12:06,089] Trial 4 finished with value: 0.980225988700565 and parameters: {'hidden_size': 57, 'learning_rate': 0.003020475950659399}. Best is trial 4 with value: 0.980225988700565.\n",
      "[I 2023-12-09 13:12:12,794] Trial 5 finished with value: 0.9265536723163842 and parameters: {'hidden_size': 164, 'learning_rate': 0.00012731785154805662}. Best is trial 4 with value: 0.980225988700565.\n",
      "[I 2023-12-09 13:12:13,842] Trial 6 pruned. \n",
      "[I 2023-12-09 13:12:14,908] Trial 7 pruned. \n",
      "[I 2023-12-09 13:12:21,644] Trial 8 finished with value: 0.902542372881356 and parameters: {'hidden_size': 159, 'learning_rate': 6.327089068227431e-05}. Best is trial 4 with value: 0.980225988700565.\n",
      "[I 2023-12-09 13:12:22,114] Trial 9 pruned. \n",
      "[I 2023-12-09 13:12:24,043] Trial 10 pruned. \n",
      "[I 2023-12-09 13:12:24,462] Trial 11 pruned. \n",
      "[I 2023-12-09 13:12:26,171] Trial 12 pruned. \n",
      "[I 2023-12-09 13:12:26,862] Trial 13 pruned. \n",
      "[I 2023-12-09 13:12:27,519] Trial 14 pruned. \n",
      "[I 2023-12-09 13:12:29,010] Trial 15 pruned. \n",
      "[I 2023-12-09 13:12:29,613] Trial 16 pruned. \n",
      "[I 2023-12-09 13:12:31,218] Trial 17 pruned. \n",
      "[I 2023-12-09 13:12:33,186] Trial 18 pruned. \n",
      "[I 2023-12-09 13:12:34,072] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.980225988700565\n",
      "Params: \n",
      "hidden_size: 57\n",
      "learning_rate: 0.003020475950659399\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "    # 初始化模型\n",
    "    model = SpamClassifier(input_size, hidden_size, output_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 训练模型\n",
    "    num_epochs = 5  # 可以根据实际情况调整\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # 在每个epoch结束后记录损失\n",
    "        trial.report(total_loss, epoch)\n",
    "\n",
    "        # 判断是否应该提前停止训练\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # 返回验证集上的准确度作为目标值\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_tensor)\n",
    "        val_loss = criterion(val_output.squeeze(), y_val_tensor)\n",
    "        val_preds = (val_output.squeeze() >= 0.5).float()\n",
    "        accuracy = torch.sum(val_preds == y_val_tensor).item() / len(y_val_tensor)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# 创建Optuna试验对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  # 设置n_trials为你希望尝试的不同超参数组合的次数\n",
    "\n",
    "# 打印最佳超参数和目标值\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Value: {}'.format(trial.value))\n",
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('{}: {}'.format(key, value))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:12:34.079284100Z",
     "start_time": "2023-12-09T05:11:42.433457900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 输出"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4193185647328695\n",
      "Epoch 2/10, Loss: 0.08081443049013615\n",
      "Epoch 3/10, Loss: 0.027794528814653555\n",
      "Epoch 4/10, Loss: 0.010755651630461216\n",
      "Epoch 5/10, Loss: 0.004661946516070101\n",
      "Epoch 6/10, Loss: 0.0028451162649111615\n",
      "Epoch 7/10, Loss: 0.0019019572193630868\n",
      "Epoch 8/10, Loss: 0.0015047467559472555\n",
      "Epoch 9/10, Loss: 0.0010434836362643789\n",
      "Epoch 10/10, Loss: 0.0008183863486111578\n"
     ]
    }
   ],
   "source": [
    "# 使用最佳超参数重新训练模型\n",
    "best_hidden_size = study.best_params['hidden_size']\n",
    "best_learning_rate = study.best_params['learning_rate']\n",
    "\n",
    "# 初始化模型\n",
    "best_model = SpamClassifier(input_size, best_hidden_size, output_size)\n",
    "best_optimizer = optim.Adam(best_model.parameters(), lr=best_learning_rate)\n",
    "best_criterion = nn.BCELoss()\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10  # 可以根据实际情况调整\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        best_optimizer.zero_grad()\n",
    "        output = best_model(batch_X)\n",
    "        loss = best_criterion(output.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        best_optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:12:39.171289100Z",
     "start_time": "2023-12-09T05:12:34.081239100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content label\n",
      "0  We are pleased to inform that your application...   ham\n",
      "1      What happen dear. Why you silent. I am tensed   ham\n",
      "2  I'll get there at 3, unless you guys want me t...   ham\n",
      "3           If you are not coughing then its nothing   ham\n",
      "4                     ÌÏ come lt 25 n pass to me lar   ham\n"
     ]
    }
   ],
   "source": [
    "# 需要预测的真实测试集\n",
    "real_x = df_te['content']\n",
    "real_x.shape\n",
    "\n",
    "# 在测试集上进行预测\n",
    "real_x_vec = vectorizer.transform(real_x)\n",
    "real_x_tensor = torch.tensor(real_x_vec.toarray(), dtype=torch.float32)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = best_model(real_x_tensor)\n",
    "    test_preds = (test_output.squeeze() >= 0.5).float()\n",
    "\n",
    "# 将预测结果转换为 DataFrame\n",
    "df_result = pd.DataFrame({'content': real_x, 'prediction': test_preds.numpy()})\n",
    "\n",
    "# 如果 prediction 列的值为 1，则代表 spam；否则，为 ham\n",
    "df_result['label'] = df_result['prediction'].apply(lambda x: 'spam' if x == 1 else 'ham')\n",
    "df_result = df_result[['content', 'label']]\n",
    "\n",
    "# 查看预测结果\n",
    "print(df_result.head())\n",
    "\n",
    "with open('submission_lstm.txt', 'w', encoding='utf-8') as f:\n",
    "    for res in df_result['label']:\n",
    "        f.write(res + '\\n')\n",
    "    # f.write('\\n'.join(pred_list_lstm))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T05:12:39.303486300Z",
     "start_time": "2023-12-09T05:12:39.167380300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1987,
     "status": "ok",
     "timestamp": 1700177915255,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "kpzPWwmcV0am",
    "outputId": "67a512fd-30e9-4eef-9f8a-824818703ec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7db829aa6630>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'     # Apple M 系列芯片可选 mps 加速\n",
    "model_path = 'distilbert-base-uncased'                      # 可以指定本地路径\n",
    "torch.manual_seed(3407)                                     # 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700177915256,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "r9v1Sv1-WL8x"
   },
   "outputs": [],
   "source": [
    "# 再次声明检测编码函数\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700177915256,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "lgWsY76TWNZ1"
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 自定义数据集\n",
    "class SpamHamDataset(Dataset):\n",
    "    def __init__(self, file_path) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(file_path, encoding=detect_encoding(file_path))\n",
    "        self.data = self.data[['v1', 'v2']].rename(columns={'v1': 'label', 'v2': 'content'})\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]['content'], self.data.iloc[index]['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2438,
     "status": "ok",
     "timestamp": 1700177917692,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "P0gAra2bWbBw",
    "outputId": "f9ed36f3-0042-4f3b-9216-edc4999efbea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'ham')\n",
      "('Ok lar... Joking wif u oni...', 'ham')\n",
      "(\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'spam')\n",
      "('U dun say so early hor... U c already then say...', 'ham')\n",
      "(\"Nah I don't think he goes to usf, he lives around here though\", 'ham')\n"
     ]
    }
   ],
   "source": [
    "ds = SpamHamDataset('train.csv')\n",
    "\n",
    "# 查看\n",
    "for i in range(5):\n",
    "    print(ds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1700177917692,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "uCrowBrEWite",
    "outputId": "71dc50f3-43ae-406a-ade5-dffc88fa8c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830, 707)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集，验证集\n",
    "# 8 : 2\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "tr_ds, val_ds = random_split(ds, lengths=[0.8, 0.2])    # train_dataset, valid_dataset\n",
    "len(tr_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1700178019675,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "jiFtA2GcW677"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    use_fast=True,  # 快速分词器\n",
    ")\n",
    "\n",
    "# Collator\n",
    "def collate_fn(batch):\n",
    "    contents, labels = [], []\n",
    "    for item in batch:\n",
    "        contents.append(item[0])\n",
    "        labels.append(1 if item[1] == 'spam' else 0)\n",
    "    # max_length 是前面的 0.99 分位点\n",
    "    inputs = tokenizer(contents, max_length=288, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    inputs['labels'] = torch.tensor(labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700178026629,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "mF_F4qwBXME2"
   },
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700178027249,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "5cdYeF07XPmx",
    "outputId": "6900b61d-6ba1-491b-c424-4c32bf7a0cd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3449,  4135,  ...,     0,     0,     0],\n",
       "        [  101,  2074,  8025,  ...,     0,     0,     0],\n",
       "        [  101,  2053,  2053,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  7929,  1012,  ...,     0,     0,     0],\n",
       "        [  101,  2027,  2207,  ...,     0,     0,     0],\n",
       "        [  101, 11948,  2072,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看一下\n",
    "next(enumerate(tr_loader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700178102106,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "ApTk66YxXel3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 评估函数\n",
    "def evaluate(model, dataset, loader):\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(loader):\n",
    "            if device == 'cuda':\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch['labels'].long()).float().sum()\n",
    "\n",
    "    return acc_num / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700178102106,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "buWoLFPbXlOV"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# 训练函数\n",
    "def train(model, optimizer, num_epochs=3, logging_steps=50):\n",
    "    global_step = 0\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"current epoch: {epoch + 1} {'=' * 80}\", flush=True)\n",
    "        model.train()\n",
    "\n",
    "        for batch in tqdm(tr_loader):\n",
    "            if device == 'cuda':\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (global_step + 1) % logging_steps == 0:\n",
    "                print(f'\\nsteps: {global_step}, loss: {output.loss.item()}', flush=True)\n",
    "            global_step += 1\n",
    "\n",
    "        # 每个 epoch 后都进行评估\n",
    "        acc = evaluate(model, val_ds, val_loader)\n",
    "        print(f'\\naccuracy: {acc}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Spn1RGe9dQun"
   },
   "source": [
    "#### 3.2.3 未调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700175883093,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "TW5viP3EYJJ5"
   },
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "logging_steps = 50\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700175665974,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "mJ0RHHT2XbB9"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 优化器选用 AdamW\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1538,
     "status": "ok",
     "timestamp": 1700177930577,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "BABhWTTgXSFO",
    "outputId": "59eba68e-d6d1-4bf9-debb-e7bd27d2f1bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# 加载 distil-bert-cased 模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126164,
     "status": "ok",
     "timestamp": 1700176011609,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "xEumxOlxX3rE",
    "outputId": "9bdb3818-98f7-4d7f-9f1a-fd8371d290ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 1 ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 49/89 [00:21<00:15,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 49, loss: 0.04640495404601097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:36<00:00,  2.42it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9915134310722351\n",
      "current epoch: 2 ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 10/89 [00:03<00:30,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 99, loss: 0.009304738603532314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 60/89 [00:23<00:11,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 149, loss: 0.041676074266433716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:35<00:00,  2.51it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9929279088973999\n",
      "current epoch: 3 ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 21/89 [00:08<00:27,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 199, loss: 0.14585527777671814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 71/89 [00:29<00:07,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 249, loss: 0.0033556544221937656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:36<00:00,  2.43it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9929279088973999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "train(model, optimizer, num_epochs, logging_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVinCXsVV9g8"
   },
   "source": [
    "#### 3.2.4 Optuna 自动调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1700178118427,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "UesDtaGXV_By"
   },
   "outputs": [],
   "source": [
    "# 定义目标函数，供 Optuna 调用\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "logging_steps = 100\n",
    "\n",
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-3, 1e-1, log=True)\n",
    "    eps = trial.suggest_float('eps', 1e-9, 1e-6, log=True)\n",
    "    params = {\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'eps': eps,\n",
    "    }\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "    )\n",
    "    optimizer = optim.AdamW(model.parameters(), **params)\n",
    "\n",
    "    global_step = 0\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    for batch in tqdm(tr_loader):\n",
    "        if device == 'cuda':\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        output = model(**batch)\n",
    "        output.loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (global_step + 1) % logging_steps == 0:\n",
    "            print(f'\\nsteps: {global_step}, loss: {output.loss.item()}', flush=True)\n",
    "        global_step += 1\n",
    "\n",
    "    # 进行评估\n",
    "    acc = evaluate(model, val_ds, val_loader)\n",
    "    print(f'\\naccuracy: {acc}', flush=True)\n",
    "\n",
    "    return acc  # Optuna 追求最大化目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3856916,
     "status": "ok",
     "timestamp": 1700181979119,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "l5c3TL_Wevnq",
    "outputId": "b18edff3-7e2c-42b5-f77b-004c7e047c01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-16 23:42:01,852] A new study created in memory with name: no-name-b22aba35-a556-4091-ae4b-2581b7d27cb1\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]\n",
      "100%|██████████| 12/12 [00:05<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:43:11,093] Trial 0 finished with value: 0.984441339969635 and parameters: {'lr': 0.00016611072831035025, 'weight_decay': 0.005146360255320083, 'eps': 2.8255957301958363e-08}. Best is trial 0 with value: 0.984441339969635.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:06<00:00,  1.34it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:44:25,560] Trial 1 finished with value: 0.984441339969635 and parameters: {'lr': 0.00013983639078775833, 'weight_decay': 0.004011445474443229, 'eps': 2.820395639014507e-07}. Best is trial 0 with value: 0.984441339969635.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:45:42,783] Trial 2 finished with value: 0.9886845946311951 and parameters: {'lr': 2.157384563749783e-05, 'weight_decay': 0.025599128679594668, 'eps': 1.5378295332367747e-09}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.8656294345855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:46:59,695] Trial 3 finished with value: 0.8656294345855713 and parameters: {'lr': 0.00041837719915014055, 'weight_decay': 0.07679022794975604, 'eps': 2.203502601160044e-07}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.29it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.8656294345855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:48:15,949] Trial 4 finished with value: 0.8656294345855713 and parameters: {'lr': 0.0014284155710492207, 'weight_decay': 0.09638230584206718, 'eps': 1.038494037027689e-09}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.29it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.8656294345855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:49:31,954] Trial 5 finished with value: 0.8656294345855713 and parameters: {'lr': 0.005757305150872561, 'weight_decay': 0.08119435916711741, 'eps': 5.8421651033932514e-08}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:50:49,244] Trial 6 finished with value: 0.9886845946311951 and parameters: {'lr': 1.6707795368737402e-05, 'weight_decay': 0.011636356846059197, 'eps': 8.40671059297352e-07}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.987270176410675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:52:06,381] Trial 7 finished with value: 0.987270176410675 and parameters: {'lr': 7.287649970314632e-05, 'weight_decay': 0.002504036570589686, 'eps': 1.9684389039538736e-09}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:53:23,772] Trial 8 finished with value: 0.9886845946311951 and parameters: {'lr': 4.698519126754657e-05, 'weight_decay': 0.0019851300734651726, 'eps': 1.7190352884527314e-08}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:54:41,294] Trial 9 finished with value: 0.984441339969635 and parameters: {'lr': 0.0001190169191108775, 'weight_decay': 0.0014087903774218037, 'eps': 2.2527909747816582e-08}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:55:58,572] Trial 10 finished with value: 0.9886845946311951 and parameters: {'lr': 1.4972070357100176e-05, 'weight_decay': 0.021426248622943678, 'eps': 3.466744971101538e-09}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:57:15,932] Trial 11 finished with value: 0.9886845946311951 and parameters: {'lr': 1.069761928337441e-05, 'weight_decay': 0.012939833128570114, 'eps': 6.069951717165009e-07}. Best is trial 2 with value: 0.9886845946311951.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9929279088973999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:58:33,239] Trial 12 finished with value: 0.9929279088973999 and parameters: {'lr': 3.085411381943491e-05, 'weight_decay': 0.022923593042419334, 'eps': 8.254221467789509e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9900990128517151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-16 23:59:50,489] Trial 13 finished with value: 0.9900990128517151 and parameters: {'lr': 3.9397932126931857e-05, 'weight_decay': 0.03037805931261226, 'eps': 6.030630171116984e-09}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.985855758190155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:01:07,836] Trial 14 finished with value: 0.985855758190155 and parameters: {'lr': 3.687597971872973e-05, 'weight_decay': 0.03602277965900572, 'eps': 7.035292257605217e-09}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:02:25,256] Trial 15 finished with value: 0.9886845946311951 and parameters: {'lr': 3.8817872936688935e-05, 'weight_decay': 0.03725650757622905, 'eps': 8.13023472889859e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9816124439239502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:03:42,396] Trial 16 finished with value: 0.9816124439239502 and parameters: {'lr': 0.00032673942897722423, 'weight_decay': 0.006958465399061996, 'eps': 6.961054412334849e-09}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9915134310722351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:04:59,559] Trial 17 finished with value: 0.9915134310722351 and parameters: {'lr': 3.182563622164694e-05, 'weight_decay': 0.01612614193130695, 'eps': 1.1526884969711229e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:06:16,838] Trial 18 finished with value: 0.9886845946311951 and parameters: {'lr': 7.902913706568533e-05, 'weight_decay': 0.017685467364202748, 'eps': 9.758031384871458e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:07:34,431] Trial 19 finished with value: 0.9886845946311951 and parameters: {'lr': 2.0710747826541462e-05, 'weight_decay': 0.008459531787750748, 'eps': 1.618914790574783e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9900990128517151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:08:52,095] Trial 20 finished with value: 0.9900990128517151 and parameters: {'lr': 1.009698212200476e-05, 'weight_decay': 0.013560761279730134, 'eps': 3.7822555260459256e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9915134310722351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:10:09,559] Trial 21 finished with value: 0.9915134310722351 and parameters: {'lr': 3.208547968527233e-05, 'weight_decay': 0.033492108404883085, 'eps': 7.258038025003091e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9787836074829102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:11:26,916] Trial 22 finished with value: 0.9787836074829102 and parameters: {'lr': 2.9313648796329506e-05, 'weight_decay': 0.049592510299943805, 'eps': 8.349902684229545e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9915134310722351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:12:44,260] Trial 23 finished with value: 0.9915134310722351 and parameters: {'lr': 6.211497892557287e-05, 'weight_decay': 0.019145396278973315, 'eps': 1.247198668459966e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9915134310722351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:14:01,745] Trial 24 finished with value: 0.9915134310722351 and parameters: {'lr': 2.398069666149199e-05, 'weight_decay': 0.045139274204989, 'eps': 3.785923928993646e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:15:19,141] Trial 25 finished with value: 0.9886845946311951 and parameters: {'lr': 6.928384907260053e-05, 'weight_decay': 0.016835872682871816, 'eps': 1.5884611366136e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.987270176410675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:16:36,312] Trial 26 finished with value: 0.987270176410675 and parameters: {'lr': 2.801730536629931e-05, 'weight_decay': 0.0267930794067874, 'eps': 4.313066825824891e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:17:53,697] Trial 27 finished with value: 0.9886845946311951 and parameters: {'lr': 1.668528921394491e-05, 'weight_decay': 0.055420374188570126, 'eps': 5.113611088506606e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9702970385551453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:19:10,714] Trial 28 finished with value: 0.9702970385551453 and parameters: {'lr': 0.00021295795686374528, 'weight_decay': 0.010403699776741167, 'eps': 2.448773248435271e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.987270176410675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:20:27,935] Trial 29 finished with value: 0.987270176410675 and parameters: {'lr': 0.00011024059254273973, 'weight_decay': 0.024761899098798067, 'eps': 3.586156661588314e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9915134310722351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:21:45,258] Trial 30 finished with value: 0.9915134310722351 and parameters: {'lr': 4.7246592545428835e-05, 'weight_decay': 0.015276356145107134, 'eps': 1.0614204458750834e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9674682021141052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:23:02,961] Trial 31 finished with value: 0.9674682021141052 and parameters: {'lr': 5.0589828877234616e-05, 'weight_decay': 0.018883258346354393, 'eps': 1.4058063331568052e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9773691892623901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:24:20,776] Trial 32 finished with value: 0.9773691892623901 and parameters: {'lr': 6.499437535053576e-05, 'weight_decay': 0.018648298902757064, 'eps': 7.203428684138624e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9816124439239502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:25:38,605] Trial 33 finished with value: 0.9816124439239502 and parameters: {'lr': 2.4112907722056204e-05, 'weight_decay': 0.03261024819316187, 'eps': 2.7051746606239905e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9745403528213501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:26:56,346] Trial 34 finished with value: 0.9745403528213501 and parameters: {'lr': 0.00016708154487661797, 'weight_decay': 0.023312858061531362, 'eps': 1.2075003089274636e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:28:14,117] Trial 35 finished with value: 0.984441339969635 and parameters: {'lr': 9.70828851035395e-05, 'weight_decay': 0.007120974817277151, 'eps': 1.8253647376740082e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.985855758190155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:29:31,942] Trial 36 finished with value: 0.985855758190155 and parameters: {'lr': 3.165379477860959e-05, 'weight_decay': 0.026090195096650906, 'eps': 4.925484375439877e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9759547710418701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:30:49,614] Trial 37 finished with value: 0.9759547710418701 and parameters: {'lr': 0.00015585257506082136, 'weight_decay': 0.013808714692214995, 'eps': 9.899793983087331e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:32:07,509] Trial 38 finished with value: 0.9886845946311951 and parameters: {'lr': 5.76854521847507e-05, 'weight_decay': 0.010764389740540463, 'eps': 5.766705913227932e-08}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:33:25,022] Trial 39 finished with value: 0.984441339969635 and parameters: {'lr': 1.4941102657750505e-05, 'weight_decay': 0.06830584769922389, 'eps': 2.1316393445640937e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.983026921749115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:34:42,458] Trial 40 finished with value: 0.983026921749115 and parameters: {'lr': 7.649082397233586e-05, 'weight_decay': 0.021312629262105205, 'eps': 3.3312352213748644e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.987270176410675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:35:59,549] Trial 41 finished with value: 0.987270176410675 and parameters: {'lr': 2.4017008109452726e-05, 'weight_decay': 0.04356181987843835, 'eps': 5.057965063966636e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.985855758190155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:37:16,913] Trial 42 finished with value: 0.985855758190155 and parameters: {'lr': 2.0208510839761683e-05, 'weight_decay': 0.042575074663445685, 'eps': 3.65965140979671e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.985855758190155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:38:34,007] Trial 43 finished with value: 0.985855758190155 and parameters: {'lr': 3.336549993205505e-05, 'weight_decay': 0.031011094538463582, 'eps': 6.505225137367611e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.984441339969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:39:51,253] Trial 44 finished with value: 0.984441339969635 and parameters: {'lr': 4.7205346325652156e-05, 'weight_decay': 0.05061314576625468, 'eps': 7.410212630126495e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.987270176410675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:41:08,723] Trial 45 finished with value: 0.987270176410675 and parameters: {'lr': 1.4453052637933883e-05, 'weight_decay': 0.038045693814819835, 'eps': 2.802500238738306e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.983026921749115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:42:26,147] Trial 46 finished with value: 0.983026921749115 and parameters: {'lr': 2.358038051713459e-05, 'weight_decay': 0.02220047623866636, 'eps': 9.540857315649503e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:43:43,531] Trial 47 finished with value: 0.9886845946311951 and parameters: {'lr': 3.734186219381254e-05, 'weight_decay': 0.028245703258893393, 'eps': 2.0292006314741516e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.985855758190155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:45:00,947] Trial 48 finished with value: 0.985855758190155 and parameters: {'lr': 1.2207711364077106e-05, 'weight_decay': 0.06380537269987058, 'eps': 1.2085215001934556e-07}. Best is trial 12 with value: 0.9929279088973999.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 0.9886845946311951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2023-11-17 00:46:18,351] Trial 49 finished with value: 0.9886845946311951 and parameters: {'lr': 1.8290637254955686e-05, 'weight_decay': 0.015600596895023317, 'eps': 4.653464610768951e-07}. Best is trial 12 with value: 0.9929279088973999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lr': 3.085411381943491e-05, 'weight_decay': 0.022923593042419334, 'eps': 8.254221467789509e-07}\n",
      "Best Accuracy: 0.9929279088973999\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GAxC82ddm77"
   },
   "source": [
    "#### 3.2.5 推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700176020903,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "m7zhYy9uX5wh"
   },
   "outputs": [],
   "source": [
    "# 推断函数（没有用批推理）\n",
    "def inference(content):\n",
    "    with torch.inference_mode():\n",
    "        inputs = tokenizer(content, return_tensors='pt')\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(logits, dim=-1)\n",
    "        return 'spam' if pred.item() == 1 else 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15369,
     "status": "ok",
     "timestamp": 1700176040668,
     "user": {
      "displayName": "Jorge Limery",
      "userId": "02703735869977102912"
     },
     "user_tz": -480
    },
    "id": "rl6WvoxZYAXt",
    "outputId": "801ce85d-2a01-455a-ff76-b6946484e8e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2035/2035 [00:15<00:00, 135.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "pred_list = [inference(c) for c in tqdm(df_te['content'])]\n",
    "\n",
    "with open('submission.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(pred_list))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJ1ox+eEx3Wt8R2NlXM/fv",
   "collapsed_sections": [
    "gvIhaWk7THNh"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
